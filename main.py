# -*- coding: utf-8 -*-
import os
import time
import threading
from pathlib import Path
import subprocess
from urllib.parse import urlparse
import shutil
import base64
import uuid
import requests
import json
import google.generativeai as genai
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from styles_config import STYLES, ROOM_STYLES
from PIL import Image, ImageOps, ImageDraw
import re
import traceback
import random
import sys
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from pydantic import BaseModel
import gc
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from typing import Optional, List, Dict, Any

# ---------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
# ---------------------------------------------------------
load_dotenv()

MODEL_NAME = 'gemini-3-pro-image-preview'       # ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€
ANALYSIS_MODEL_NAME = 'gemini-3-flash-preview'  # ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€
API_KEY_POOL = []
i = 1
while True:
    key = os.getenv(f"NANOBANANA_API_KEY_{i}") 
    if not key:
        key = os.getenv(f"NANOBANANA_API_KEY{i}")
        if not key: break
    API_KEY_POOL.append(key)
    i += 1

if not API_KEY_POOL:
    single_key = os.getenv("NANOBANANA_API_KEY")
    if single_key: API_KEY_POOL.append(single_key)

print(f"âœ… ë¡œë“œëœ ë‚˜ë…¸ë°”ë‚˜ë‚˜ API í‚¤ ê°œìˆ˜: {len(API_KEY_POOL)}ê°œ", flush=True)

MAGNIFIC_API_KEY = os.getenv("MAGNIFIC_API_KEY")
MAGNIFIC_ENDPOINT = os.getenv("MAGNIFIC_ENDPOINT", "https://api.freepik.com/v1/ai/image-upscaler")
TOTAL_TIMEOUT_LIMIT = 300 

os.makedirs("outputs", exist_ok=True)
os.makedirs("assets", exist_ok=True)
os.makedirs("static", exist_ok=True)

# Periodic cleanup for outputs to avoid disk growth.
OUTPUT_CLEANUP_TTL_SEC = 12 * 60 * 60
OUTPUT_CLEANUP_INTERVAL_SEC = 60 * 60

def _cleanup_outputs_once():
    now = time.time()
    try:
        for name in os.listdir("outputs"):
            path = os.path.join("outputs", name)
            try:
                if not os.path.isfile(path):
                    continue
                if now - os.path.getmtime(path) > OUTPUT_CLEANUP_TTL_SEC:
                    os.remove(path)
            except Exception:
                pass
    except Exception:
        pass

def _start_outputs_cleanup_worker():
    def _worker():
        while True:
            _cleanup_outputs_once()
            time.sleep(OUTPUT_CLEANUP_INTERVAL_SEC)
    t = threading.Thread(target=_worker, daemon=True)
    t.start()

_start_outputs_cleanup_worker()

app = FastAPI()
@app.middleware("http")
async def log_requests(request, call_next):
    rid = uuid.uuid4().hex[:8]
    t0 = time.time()
    logger.info(f"[REQ {rid}] {request.method} {request.url.path}")
    try:
        response = await call_next(request)
        dt = (time.time() - t0) * 1000
        logger.info(f"[RES {rid}] {response.status_code} ({dt:.1f}ms) {request.url.path}")
        return response
    except Exception as e:
        dt = (time.time() - t0) * 1000
        logger.exception(f"[ERR {rid}] ({dt:.1f}ms) {request.url.path} :: {e}")
        raise

app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/outputs", StaticFiles(directory="outputs"), name="outputs")
app.mount("/assets", StaticFiles(directory="assets"), name="assets")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

QUOTA_EXCEEDED_KEYS = set()

def call_gemini_with_failover(model_name, contents, request_options, safety_settings, system_instruction=None):
    global API_KEY_POOL, QUOTA_EXCEEDED_KEYS
    max_retries = len(API_KEY_POOL) + 2
    timeout_retry_used = False

    # ê°„ë‹¨í•˜ê²Œ payload íƒ€ì…ë§Œ ë¡œê¹… (ì´ë¯¸ì§€ëŠ” ë„ˆë¬´ í¬ë‹ˆ ê¸¸ì´ë§Œ)
    try:
        content_types = []
        for c in contents or []:
            if isinstance(c, str):
                content_types.append(f"str({len(c)})")
            else:
                content_types.append(type(c).__name__)
        logger.info(f"[Gemini] model={model_name} timeout={request_options.get('timeout')} contents={content_types}")
    except Exception:
        pass

    for attempt in range(max_retries):
        available_keys = [k for k in API_KEY_POOL if k not in QUOTA_EXCEEDED_KEYS]
        if not available_keys:
            logger.warning("[Gemini] All keys locked. Cooldown 5s then reset.")
            time.sleep(5)
            QUOTA_EXCEEDED_KEYS.clear()
            available_keys = list(API_KEY_POOL)

        current_key = random.choice(available_keys)
        masked_key = current_key[-4:]

        try:
            genai.configure(api_key=current_key)
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction) if system_instruction else genai.GenerativeModel(model_name)

            t0 = time.time()
            response = model.generate_content(contents, request_options=request_options, safety_settings=safety_settings)
            dt = (time.time() - t0) * 1000
            logger.info(f"[Gemini] âœ… success key=...{masked_key} ({dt:.0f}ms) model={model_name}")
            return response

        except Exception as e:
            error_msg = str(e)
            error_lower = error_msg.lower()
            is_timeout = any(x in error_lower for x in ["504", "deadline", "timeout", "timed out"])
            if is_timeout:
                if timeout_retry_used:
                    logger.error(f"[Gemini] timeout retry exhausted key=...{masked_key} attempt={attempt+1}/{max_retries} :: {error_msg[:200]}")
                    break
                timeout_retry_used = True
                logger.warning(f"[Gemini] timeout key=...{masked_key} attempt={attempt+1}/{max_retries} :: {error_msg[:200]}")
                time.sleep(1)
                continue
            if any(x in error_msg for x in ["429", "403", "Quota", "limit", "Resource has been exhausted"]):
                logger.warning(f"[Gemini] ğŸ“‰ quota key=...{masked_key} attempt={attempt+1}/{max_retries} :: {error_msg[:180]}")
                QUOTA_EXCEEDED_KEYS.add(current_key)
                time.sleep(2 + attempt)
            else:
                logger.error(f"[Gemini] âš ï¸ error key=...{masked_key} attempt={attempt+1}/{max_retries} :: {error_msg[:250]}")
                time.sleep(1)

    logger.error("[Gemini] âŒ fatal: all keys failed")
    return None

# ---------------------------------------------------------
# [LOGGING] Always-on stdout logging (works under uvicorn/gunicorn)
# ---------------------------------------------------------
def setup_logging():
    try:
        # Make stdout line-buffered so logs appear immediately
        if hasattr(sys.stdout, "reconfigure"):
            sys.stdout.reconfigure(line_buffering=True)
        if hasattr(sys.stderr, "reconfigure"):
            sys.stderr.reconfigure(line_buffering=True)
    except Exception:
        pass

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)s | %(message)s",
        handlers=[logging.StreamHandler(sys.stdout)],
        force=True,  # <-- ì¤‘ìš”: uvicornì´ ì´ë¯¸ ë¡œê¹… ì¡ì•˜ì–´ë„ ë®ì–´ì”€
    )

setup_logging()
logger = logging.getLogger("app")
logger.info("âœ… Logger initialized (stdout, line-buffered).")

def standardize_image(image_path, output_path=None, keep_ratio=False, force_landscape=False):
    try:
        if output_path is None: output_path = image_path
        with Image.open(image_path) as img:
            img = ImageOps.exif_transpose(img)
            
            # [ìˆ˜ì •] íˆ¬ëª… ë°°ê²½(RGBA) ì²˜ë¦¬: í°ìƒ‰ ì†Œí’ˆì´ í° ë°°ê²½ì— ë¬»íˆëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì¤‘ë¦½ ê·¸ë ˆì´(#D2D2D2) ë°°ê²½ ì‚¬ìš©
            if img.mode in ("RGBA", "P"):
                img = img.convert("RGBA")
                # ë°ì€ ê°€êµ¬ì™€ ì–´ë‘ìš´ ê°€êµ¬ ëª¨ë‘ ëŒ€ë¹„ê°€ ì˜ ë³´ì´ëŠ” ì¤‘ë¦½ì ì¸ íšŒìƒ‰ ë°°ê²½ ìƒì„±
                background = Image.new("RGBA", img.size, (210, 210, 210, 255)) 
                img = Image.alpha_composite(background, img).convert("RGB")
            elif img.mode != 'RGB':
                img = img.convert('RGB')

            width, height = img.size
            
            # [FIX] force_landscapeê°€ Trueë©´ -> ë¬´ì¡°ê±´ 16:9 (1920x1080) ì„¤ì •
            if force_landscape:
                target_size = (1920, 1080)
                target_ratio = 16 / 9
            # ê¸°ì¡´ ë¡œì§ (ìë™ ê°ì§€)
            elif width >= height:
                target_size = (1920, 1080)
                target_ratio = 16 / 9
            else:
                target_size = (1080, 1350)
                target_ratio = 4 / 5

            if not keep_ratio:
                current_ratio = width / height

                if current_ratio > target_ratio:
                    # ì´ë¯¸ì§€ê°€ ë” ë‚©ì‘í•œ ê²½ìš° (ì–‘ì˜† ìë¦„)
                    new_width = int(height * target_ratio)
                    offset = (width - new_width) // 2
                    img = img.crop((offset, 0, offset + new_width, height))
                else:
                    # ì´ë¯¸ì§€ê°€ ë” í™€ì­‰í•œ ê²½ìš° (ìœ„ì•„ë˜ ìë¦„)
                    new_height = int(width / target_ratio)
                    offset = (height - new_height) // 2
                    img = img.crop((0, offset, width, offset + new_height))

                # ìµœì¢… ë¦¬ì‚¬ì´ì¦ˆ (LANCZOS í•„í„° ì‚¬ìš©)
                img = img.resize(target_size, Image.Resampling.LANCZOS)

            base, _ = os.path.splitext(output_path)
            new_output_path = f"{base}.png"
            img.save(new_output_path, "PNG")
            return new_output_path
    except Exception as e:
        print(f"!! í‘œì¤€í™” ì‹¤íŒ¨: {e}", flush=True)
        return image_path
# ---------------------------------------------------------
# [NEW] Output Aspect Ratio Enforcement
# - Geminiê°€ ë¬´ë“œë³´ë“œ ë¹„ìœ¨/ë ˆì´ì•„ì›ƒì„ ë”°ë¼ê°€ê±°ë‚˜,
#   í•˜ë‹¨ì— í° ë°°ê²½(ì¹´íƒˆë¡œê·¸/í…ìŠ¤íŠ¸) ì˜ì—­ì„ ë¶™ì—¬ì„œ ë‚´ë³´ë‚´ëŠ” ì¼€ì´ìŠ¤ë¥¼
#   "ë°© ì‚¬ì§„ ìº”ë²„ìŠ¤" ê¸°ì¤€ìœ¼ë¡œ ê°•ì œ ë³´ì •í•©ë‹ˆë‹¤.
# ---------------------------------------------------------

def _is_bottom_strip_mostly_white(img: Image.Image, strip_ratio: float = 0.22, white_thresh: int = 245) -> bool:
    """í•˜ë‹¨ stripì´ 'ê±°ì˜ í°ìƒ‰'ì¸ì§€ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

    - ë¬´ë“œë³´ë“œ/ì¸ë²¤í† ë¦¬ ì‹œíŠ¸ê°€ í•˜ë‹¨ì— ë¶™ëŠ” ê²½ìš° í° ë°°ê²½ì´ ëŒ€ëŸ‰ í¬í•¨ë˜ëŠ” íŒ¨í„´ì´ ë§ì•„ì„œ
      landscape ê°•ì œ í¬ë¡­ ì‹œ 'ìœ„ìª½ ê³ ì •(top anchor)' ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        w, h = img.size
        if w <= 0 or h <= 0:
            return False

        strip_h = max(1, int(h * strip_ratio))
        y0 = max(0, h - strip_h)
        strip = img.crop((0, y0, w, h))

        # ê³„ì‚° ë¹„ìš©ì„ ë‚®ì¶”ê¸° ìœ„í•´ ì¶•ì†Œ í›„ íŒë‹¨
        strip = strip.resize((256, max(1, int(256 * strip_ratio))), Image.Resampling.BILINEAR)
        gray = strip.convert('L')
        pixels = list(gray.getdata())
        if not pixels:
            return False

        white_count = sum(1 for p in pixels if p >= white_thresh)
        white_ratio = white_count / len(pixels)

        # 35% ì´ìƒì´ ìˆœë°±(ê·¼ì²˜)ì´ë©´ "í•˜ë‹¨ì´ í° ì‹œíŠ¸"ì¼ í™•ë¥ ì´ ë†’ë‹¤ê³  ê°€ì •
        return white_ratio >= 0.35
    except Exception:
        return False


def standardize_image_to_reference_canvas(
    image_path: str,
    reference_path: str,
    output_path: Optional[str] = None,
) -> str:
    """ìƒì„± ê²°ê³¼ë¬¼ì„ 'reference ì´ë¯¸ì§€(=ë¹ˆ ë°© ìº”ë²„ìŠ¤)'ì˜ ë¹„ìœ¨/í•´ìƒë„ë¡œ ê°•ì œ í†µì¼í•©ë‹ˆë‹¤.

    - í•µì‹¬: ë¬´ë“œë³´ë“œê°€ ì„¸ë¡œì—¬ë„ ìµœì¢… ê²°ê³¼ëŠ” ë°© ì‚¬ì§„ ìº”ë²„ìŠ¤(16:9 ë˜ëŠ” 4:5)ë¡œ ê°•ì œ.
    - ì¶”ê°€: ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì„¸ë¡œë¡œ íŠ€ë©´ì„œ í•˜ë‹¨ì— í° ì¸ë²¤í† ë¦¬ ì˜ì—­ì´ ë¶™ëŠ” ì¼€ì´ìŠ¤ë¥¼
            top-anchor í¬ë¡­ìœ¼ë¡œ ì˜ë¼ë‚´ëŠ” íœ´ë¦¬ìŠ¤í‹±ì„ ì ìš©.
    """
    try:
        with Image.open(reference_path) as ref_img:
            ref_img = ImageOps.exif_transpose(ref_img)
            ref_w, ref_h = ref_img.size
            if ref_w <= 0 or ref_h <= 0:
                return image_path

        with Image.open(image_path) as img:
            img = ImageOps.exif_transpose(img)
            if img.mode != 'RGB':
                img = img.convert('RGB')

            w, h = img.size
            if w <= 0 or h <= 0:
                return image_path

            target_ratio = ref_w / ref_h
            current_ratio = w / h

            # ì´ë¯¸ ëª©í‘œ ìº”ë²„ìŠ¤ì™€ ë™ì¼í•˜ë©´ ê·¸ëŒ€ë¡œ PNGë¡œë§Œ ì €ì¥ (ì•ˆì „)
            if abs(current_ratio - target_ratio) < 1e-3 and (w, h) == (ref_w, ref_h):
                base, _ = os.path.splitext(output_path or image_path)
                out_path = f"{base}.png"
                img.save(out_path, "PNG")
                return out_path

            if current_ratio > target_ratio:
                # ë„ˆë¬´ ë„“ìŒ: ì¢Œìš° í¬ë¡­
                new_w = int(h * target_ratio)
                x0 = max(0, (w - new_w) // 2)
                img = img.crop((x0, 0, x0 + new_w, h))
            else:
                # ë„ˆë¬´ ë†’ìŒ: ìƒí•˜ í¬ë¡­
                new_h = int(w / target_ratio)
                new_h = min(new_h, h)

                # í•˜ë‹¨ì— í° ì‹œíŠ¸ê°€ ë¶™ëŠ” íŒ¨í„´ì´ë©´ ìœ„ìª½ ê¸°ì¤€ìœ¼ë¡œ í¬ë¡­ (í•˜ë‹¨ ì œê±°)
                if ref_w >= ref_h and _is_bottom_strip_mostly_white(img):
                    y0 = 0
                else:
                    y0 = max(0, (h - new_h) // 2)

                img = img.crop((0, y0, w, y0 + new_h))

            img = img.resize((ref_w, ref_h), Image.Resampling.LANCZOS)

            base, _ = os.path.splitext(output_path or image_path)
            out_path = f"{base}_fit.png"
            img.save(out_path, "PNG")
            return out_path
    except Exception as e:
        print(f"!! [Canvas Fit Failed] {e}", flush=True)
        return image_path

# -----------------------------------------------------------------------------
# [CORE] Analysis Logic (Global Definition)
# -----------------------------------------------------------------------------

# =============================================================================
# [SCALE FIX PACK vB] Robust dimension parsing + furniture spec JSON + auto-pick
# - Keeps existing rendering behavior; only strengthens SCALE guidance & selection.
# - Primary anchor furniture = largest-volume movable furniture EXCLUDING rugs/carpets.
# =============================================================================

_RUG_KEYWORDS = [
    "fabric rug", "large rug", "rug", "carpet", "mat",
    "ëŸ¬ê·¸", "ì¹´í˜íŠ¸", "ì¹´í«",
]

def _is_rug_like(label: str) -> bool:
    try:
        s = (label or "").strip().lower()
        if not s:
            return False
        for kw in _RUG_KEYWORDS:
            if kw in s:
                if kw == "mat":
                    if re.search(r"\bmat\b", s):
                        return True
                    continue
                return True
        return False
    except Exception:
        return False

def _to_mm(value: float, unit: Optional[str]) -> int:
    """Convert value to mm. If unit missing, heuristic: >=50 -> mm else meters."""
    u = (unit or "").strip().lower()
    try:
        if u in ("mm",):
            return int(round(value))
        if u in ("cm",):
            return int(round(value * 10.0))
        if u in ("m", "meter", "metre"):
            return int(round(value * 1000.0))
        if value <= 20.0:
            return int(round(value * 1000.0))
        return int(round(value))
    except Exception:
        return 0

_DIM_KEY_PATTERNS = {
    "width_mm":  r"(?:\bW\b|width|ê°€ë¡œ|í­|ë„ˆë¹„)\s*[:=]?\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?",
    "depth_mm":  r"(?:\bD\b|depth|ì„¸ë¡œ|ê¹Šì´)\s*[:=]?\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?",
    "height_mm": r"(?:\bH\b|height|ë†’ì´)\s*[:=]?\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?",
}

_TRIPLE_PATTERNS = [
    r"([0-9][0-9,\.]*)\s*(mm|cm|m)?\s*[xÃ—X]\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?\s*[xÃ—X]\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?",
    r"\bW\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?\s*\bD\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?\s*\bH\s*([0-9][0-9,\.]*)\s*(mm|cm|m)?",
]

def parse_object_dimensions_mm(text: str) -> dict:
    t = (text or "")
    t_norm = t.replace("ï¼Œ", ",").replace("Ã—", "x")
    out = {"width_mm": None, "depth_mm": None, "height_mm": None, "raw": {}}

    for pat in _TRIPLE_PATTERNS:
        m = re.search(pat, t_norm, flags=re.IGNORECASE)
        if not m:
            continue
        n1, u1, n2, u2, n3, u3 = m.groups()
        def _num(s): return float(str(s).replace(",", ""))
        w = _to_mm(_num(n1), u1)
        d = _to_mm(_num(n2), u2 or u1)
        h = _to_mm(_num(n3), u3 or u2 or u1)
        if w: out["width_mm"] = w
        if d: out["depth_mm"] = d
        if h: out["height_mm"] = h
        out["raw"]["triple"] = m.group(0)
        return out

    for k, pat in _DIM_KEY_PATTERNS.items():
        m = re.search(pat, t_norm, flags=re.IGNORECASE)
        if not m:
            continue
        num_str, unit = m.group(1), m.group(2)
        try:
            v = float(num_str.replace(",", ""))
        except Exception:
            continue
        mm = _to_mm(v, unit)
        if mm:
            out[k] = mm
            out["raw"][k] = m.group(0)

    return out

def parse_room_dimensions_mm(text: str) -> dict:
    t = (text or "").strip()
    if not t:
        return {"width_mm": 0, "depth_mm": 0, "height_mm": 0}
    t_norm = t.replace("ï¼Œ", ",").replace("Ã—", "x").replace("X", "x")

    m = re.search(_TRIPLE_PATTERNS[0], t_norm, flags=re.IGNORECASE)
    if m:
        n1,u1,n2,u2,n3,u3 = m.groups()
        def _num(s): return float(str(s).replace(",", ""))
        w = _to_mm(_num(n1), u1)
        d = _to_mm(_num(n2), u2 or u1)
        h = _to_mm(_num(n3), u3 or u2 or u1)
        return {"width_mm": w or 0, "depth_mm": d or 0, "height_mm": h or 0}

    parts = re.findall(r"([0-9][0-9,\.]*)\s*(mm|cm|m)?", t_norm, flags=re.IGNORECASE)
    nums = []
    for num_str, unit in parts:
        try:
            v = float(num_str.replace(",", ""))
        except Exception:
            continue
        nums.append(_to_mm(v, unit))
    nums = [n for n in nums if n > 0]
    if not nums:
        return {"width_mm": 0, "depth_mm": 0, "height_mm": 0}
    if len(nums) == 1:
        return {"width_mm": nums[0], "depth_mm": 0, "height_mm": 0}
    if len(nums) == 2:
        return {"width_mm": nums[0], "depth_mm": nums[1], "height_mm": 0}
    return {"width_mm": nums[0], "depth_mm": nums[1], "height_mm": nums[2]}

def _volume_proxy(dims: dict) -> int:
    try:
        w = int(dims.get("width_mm") or 0)
        d = int(dims.get("depth_mm") or 0)
        h = int(dims.get("height_mm") or 0)
        if w and d and h: return w*d*h
        if w and d: return w*d
        if w: return w
    except Exception:
        pass
    return 0

def build_furniture_specs_json(analyzed_items: list) -> dict:
    items = []
    
    # [FIX] ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ ì •ì˜ (ì´ ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´ ê°€ì¤‘ì¹˜ ë¶€ì—¬)
    PRIORITY_KEYWORDS = {
        "sofa": 100, "couch": 100, "sectional": 100,
        "bed": 90, 
        "table": 80, "desk": 80, "dining": 80,
        "console": 60, "shelf": 60, "cabinet": 60, "storage": 60,
        "tv": 50,
        "chair": 40, "armchair": 40,
        "lamp": 10, "light": 10, "plant": 5
    }

    for i, it in enumerate(analyzed_items or []):
        label = it.get("label", "") or ""
        desc  = it.get("description", "") or ""
        box   = it.get("box_2d")
        
        # 1. ì¹˜ìˆ˜ íŒŒì‹± ì‹œë„ (ë¶„ì„ëœ descriptionì—ì„œ)
        dims = parse_object_dimensions_mm(desc)
        
        # 2. ëŸ¬ê·¸ íŒë‹¨
        is_rug = _is_rug_like(label)
        
        # 3. ë¶€í”¼ ëŒ€ìš©ê°’ ê³„ì‚° (ë†’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1000mm ê°€ì •í•˜ì—¬ 0 ë°©ì§€)
        w = dims.get("width_mm") or 0
        d = dims.get("depth_mm") or 0
        h = dims.get("height_mm") or 1000 
        vp = (w * d * h) if (w or d) else 0
        if is_rug: vp = 0 # ëŸ¬ê·¸ëŠ” ê¸°ì¤€ì  ì œì™¸

        # 4. ì¹´í…Œê³ ë¦¬ ì ìˆ˜ ê³„ì‚°
        cat_score = 0
        norm_label = label.lower()
        for key, score in PRIORITY_KEYWORDS.items():
            if key in norm_label:
                cat_score = max(cat_score, score)
        
        items.append({
            "index": i,
            "label": label,
            "is_rug": is_rug,
            "category_score": cat_score, # [NEW]
            "dims_mm": {
                "width_mm": dims.get("width_mm"),
                "depth_mm": dims.get("depth_mm"),
                "height_mm": dims.get("height_mm"),
            },
            "volume_proxy": vp,
            "box_2d": box,
            "description": desc,
            "crop_path": (it.get("crop_path") if isinstance(it, dict) else None),
        })

    primary = None
    # [FIX] ê¸°ì¤€ì  ì„ ì • ë¡œì§ ê°•í™”: (ì¹´í…Œê³ ë¦¬ ì ìˆ˜ > ë¶€í”¼ > ì¸ë±ìŠ¤)
    candidates = [x for x in items if not x["is_rug"]]
    if candidates:
        # Sort key: 1. Category Score (desc), 2. Volume (desc), 3. Index (asc)
        candidates_sorted = sorted(candidates, key=lambda x: (x["category_score"], x["volume_proxy"], -x["index"]), reverse=True)
        primary = candidates_sorted[0]

    # Max width fallback
    max_width_mm = 0
    for x in candidates:
        w = x.get("dims_mm", {}).get("width_mm") or 0
        try:
            max_width_mm = max(max_width_mm, int(w))
        except Exception: pass

    try:
        if primary and max_width_mm and not (primary.get("dims_mm", {}) or {}).get("width_mm"):
            primary.setdefault("dims_mm", {})["width_mm"] = int(max_width_mm)
    except Exception: pass

    hierarchy = [x.get("label","") for x in (analyzed_items or []) if not _is_rug_like(x.get("label",""))]
    return {"items": items, "primary": primary, "max_width_mm": max_width_mm, "size_hierarchy": hierarchy}

def _safe_json_from_model_text(txt: str):
    if not txt: return None
    t = txt.strip()
    try:
        if "```json" in t:
            t = t.split("```json", 1)[1].split("```", 1)[0].strip()
        elif "```" in t:
            t = t.split("```", 1)[1].split("```", 1)[0].strip()
    except Exception:
        pass
    try:
        return json.loads(t)
    except Exception:
        pass
    try:
        a = t.find("{"); b = t.rfind("}")
        if a != -1 and b != -1 and b > a:
            return json.loads(t[a:b+1])
    except Exception:
        pass
    return None

def detect_back_wall_span_norm(empty_room_path: str) -> tuple:
    try:
        with Image.open(empty_room_path) as img:
            prompt = (
                "TASK: ROOM GEOMETRY MEASUREMENT.\\n"
                "In this empty room photo, find the BACK WALL usable span where main furniture would sit.\\n"
                "Return STRICT JSON ONLY: {\\\"x_left\\\":0.0, \\\"x_right\\\":1.0} using normalized [0..1].\\n"
                "Use the floor-wall boundary; ignore doors/windows if they reduce usable span. Approximate if unsure."
            )
            res = call_gemini_with_failover(ANALYSIS_MODEL_NAME, [prompt, img], {"timeout": 20}, {})
            obj = _safe_json_from_model_text(res.text if res and hasattr(res, "text") else "")
            if isinstance(obj, dict):
                xl = float(obj.get("x_left", 0.0)); xr = float(obj.get("x_right", 1.0))
                xl = max(0.0, min(1.0, xl)); xr = max(0.0, min(1.0, xr))
                if xr - xl >= 0.2:
                    return (xl, xr)
    except Exception:
        pass
    return (0.0, 1.0)

def _crop_ref_item_image(ref_path: str, box_2d: list, out_path: str):
    try:
        if not box_2d:
            return None
        with Image.open(ref_path) as img:
            w, h = img.size
            ymin, xmin, ymax, xmax = box_2d
            left = int(xmin / 1000 * w); top = int(ymin / 1000 * h)
            right = int(xmax / 1000 * w); bottom = int(ymax / 1000 * h)
            left = max(0, min(w-1, left)); right = max(left+1, min(w, right))
            top = max(0, min(h-1, top)); bottom = max(top+1, min(h, bottom))
            crop = img.crop((left, top, right, bottom))
            crop.save(out_path, "PNG")
            return out_path
    except Exception:
        return None

def create_scale_guide_image(empty_room_path: str, wall_span_norm: tuple, target_ratio: float, out_path: str):
    try:
        with Image.open(empty_room_path) as base_img:
            base = base_img.convert("RGBA")
            W, H = base.size
            xl, xr = wall_span_norm if wall_span_norm else (0.0, 1.0)
            span_px = max(1, int((xr - xl) * W))
            target_px = int(max(1, min(span_px, span_px * float(target_ratio))))
            x_center = int((xl + xr) * 0.5 * W)
            x1 = int(max(0, min(W-1, x_center - target_px//2)))
            x2 = int(max(0, min(W-1, x_center + target_px//2)))

            overlay = Image.new("RGBA", (W, H), (0, 0, 0, 0))
            draw = ImageDraw.Draw(overlay)
            line = (255, 0, 0, 110)
            thick = 4
            for dx in range(-thick//2, thick//2 + 1):
                draw.line([(x1+dx, 0), (x1+dx, H)], fill=line, width=1)
                draw.line([(x2+dx, 0), (x2+dx, H)], fill=line, width=1)

            wall_line = (0, 255, 255, 80)
            draw.line([(int(xl*W), H-5), (int(xr*W), H-5)], fill=wall_line, width=3)

            composed = Image.alpha_composite(base, overlay).convert("RGB")
            composed.save(out_path, "PNG")
            return out_path
    except Exception:
        return None

def detect_primary_bbox_norm(staged_path: str, ref_item_crop_path: Optional[str], primary_label: Optional[str]):
    try:
        with Image.open(staged_path) as img:
            prompt = (
                "OBJECT LOCALIZATION TASK.\\n"
                "Find the PRIMARY ANCHOR furniture in the staged room image.\\n"
                "Return STRICT JSON ONLY: {\\\"xmin\\\":0.0,\\\"ymin\\\":0.0,\\\"xmax\\\":1.0,\\\"ymax\\\":1.0}.\\n"
                "bbox must tightly cover only that furniture. If reference crop is provided, match that object."
            )
            content = [prompt, "Staged room image:", img]
            if primary_label:
                content.insert(1, f"Primary label hint: {primary_label}")
            ref_img = None
            try:
                if ref_item_crop_path and os.path.exists(ref_item_crop_path):
                    ref_img = Image.open(ref_item_crop_path)
                    content += ["Reference item crop:", ref_img]
                res = call_gemini_with_failover(ANALYSIS_MODEL_NAME, content, {"timeout": 20}, {})
            finally:
                if ref_img:
                    ref_img.close()
            obj = _safe_json_from_model_text(res.text if res and hasattr(res, "text") else "")
            if isinstance(obj, dict):
                xmin = float(obj.get("xmin", 0.0)); xmax = float(obj.get("xmax", 1.0))
                ymin = float(obj.get("ymin", 0.0)); ymax = float(obj.get("ymax", 1.0))
                xmin = max(0.0, min(1.0, xmin)); xmax = max(0.0, min(1.0, xmax))
                ymin = max(0.0, min(1.0, ymin)); ymax = max(0.0, min(1.0, ymax))
                if xmax - xmin > 0.05 and ymax - ymin > 0.05:
                    return (xmin, ymin, xmax, ymax)
    except Exception:
        pass
    return None

def _score_scale(bbox_norm: tuple, wall_span_norm: tuple, target_ratio: float) -> float:
    try:
        xmin, ymin, xmax, ymax = bbox_norm
        xl, xr = wall_span_norm if wall_span_norm else (0.0, 1.0)
        span = max(1e-6, (xr - xl))
        w = max(1e-6, (xmax - xmin))
        actual = w / span
        target = max(1e-6, float(target_ratio))
        err = abs(actual - target)
        tol = max(0.08, target * 0.20)
        score = 1.0 - min(1.0, err / tol)
        return float(max(0.0, min(1.0, score)))
    except Exception:
        return 0.0

def reorder_by_scale_best_pick(result_urls: list, ref_path: str, primary: dict, room_dims: dict, wall_span_norm: tuple) -> list:
    try:
        room_w = int(room_dims.get("width_mm") or 0)
        p_w = int((primary.get("dims_mm") or {}).get("width_mm") or 0)
        if room_w <= 0 or p_w <= 0:
            return result_urls
        target_ratio = p_w / room_w

        ref_crop = None
        try:
            out_crop = os.path.join("outputs", f"ref_primary_{uuid.uuid4().hex[:8]}.png")
            ref_crop = _crop_ref_item_image(ref_path, primary.get("box_2d"), out_crop) if primary.get("box_2d") else None
        except Exception:
            ref_crop = None

        scored = []
        for idx, url in enumerate(result_urls or []):
            local = os.path.join("outputs", os.path.basename(url))
            bbox = detect_primary_bbox_norm(local, ref_crop, primary.get("label"))
            if bbox is None:
                scored.append((0.0, idx, url))
                continue
            s = _score_scale(bbox, wall_span_norm, target_ratio)
            scored.append((s, idx, url))

        scored.sort(key=lambda x: (x[0], -x[1]), reverse=True)
        return [u for _, _, u in scored]
    except Exception:
        return result_urls

def detect_furniture_boxes(moodboard_path):
    print(f">> [Detection] Scanning furniture in {moodboard_path}...", flush=True)
    try:
        with Image.open(moodboard_path) as img:
            prompt = (
                "OBJECT DETECTION TASK:\n"
                "Identify ALL discrete furniture items in this image (Sofa, Chair, Table, Lamp, Rug, Ottoman, etc.).\n"
                "**NOTE:** The background is a neutral grey (#D2D2D2) for contrast. Do not detect the background itself.\n"
                "Return a JSON list where each item has:\n"
                "- 'label': Name of the item.\n"
                "- 'box_2d': [ymin, xmin, ymax, xmax] coordinates normalized to 0-1000 scale.\n"
                "\n"
                "<CRITICAL: SORTING ORDER>\n"
                "**YOU MUST SORT THE LIST BY PHYSICAL SIZE (VOLUME) FROM LARGEST TO SMALLEST.**\n"
                "1. Largest items first (e.g., Sofa, Bed, Large Rug, Wardrobe).\n"
                "2. Medium items second (e.g., Armchair, Coffee Table, Console).\n"
                "3. Small items last (e.g., Side Table, Lamp, Vase, Decor).\n"
                "Ignore walls, windows, and floors. Focus on movable objects."
            )
            response = call_gemini_with_failover(ANALYSIS_MODEL_NAME, [prompt, img], {'timeout': 60}, {})
            if response and response.text:
                text = response.text.strip()
                if "```json" in text: text = text.split("```json")[1].split("```")[0].strip()
                elif "```" in text: text = text.split("```")[0].strip()
                
                items = json.loads(text)
                if isinstance(items, list) and len(items) > 0:

                    print(f">> [Detection] Found {len(items)} items (Sorted): {[i.get('label') for i in items]}", flush=True)
                    return items
    except Exception as e:
        print(f"!! Detection Failed: {e}", flush=True)
    
    return [{"label": "Main Furniture"}, {"label": "Coffee Table"}, {"label": "Lounge Chair"}]

def analyze_cropped_item(moodboard_path, item_data, unique_id=None, item_index=None, save_crop=True):
    """
    Crop detected item WITH PADDING to capture specification text below the item.
    """
    try:
        box = item_data.get('box_2d')
        label = item_data.get('label', 'Furniture')
        cropped_img = None
        
        img = Image.open(moodboard_path)
        W, H = img.size
        
        if box:
            ymin, xmin, ymax, xmax = box
            
            # [CRITICAL FIX] í…ìŠ¤íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ "ìŠ¤ë§ˆíŠ¸ íŒ¨ë”©" ì¶”ê°€
            # ë¬´ë“œë³´ë“œ íŠ¹ì„±ìƒ í…ìŠ¤íŠ¸ëŠ” ë³´í†µ ê°€êµ¬ 'ì•„ë˜'ì— ì í˜€ ìˆìŠµë‹ˆë‹¤.
            # ë°•ìŠ¤ ë†’ì´ì˜ 100% ë§Œí¼ ì•„ë˜ë¡œ ë” ìº¡ì²˜í•˜ê³ , ì¢Œìš°ë¡œë„ ì—¬ìœ ë¥¼ ì¤ë‹ˆë‹¤.
            
            box_h = ymax - ymin
            box_w = xmax - xmin
            
            # ì•„ë˜ë¡œ í™•ì¥ (í…ìŠ¤íŠ¸ ì˜ì—­ í™•ë³´)
            pad_bottom = int(box_h * 1) 
            # ì¢Œìš°ë¡œ ì•½ê°„ í™•ì¥ (ê¸€ìê°€ ì˜ë¦¬ëŠ” ê²ƒ ë°©ì§€)
            pad_x = int(box_w * 0.5)

            # ì¢Œí‘œ ë³€í™˜ (0~1000 ìŠ¤ì¼€ì¼ -> í”½ì…€)
            top = int(ymin / 1000 * H)
            # ì•„ë˜ìª½ì€ ì´ë¯¸ì§€ ëì„ ë„˜ì§€ ì•Šë„ë¡ min ì²˜ë¦¬
            bottom = int(min(1000, ymax + pad_bottom) / 1000 * H) 
            
            left = int(max(0, xmin - pad_x) / 1000 * W)
            right = int(min(1000, xmax + pad_x) / 1000 * W)

            # í¬ë¡­ ì‹¤í–‰
            cropped_img = img.crop((left, top, right, bottom))
        else:
            cropped_img = img.copy()

        img.close()

        # [A-Variant] Optionally save the cropped item image for cutout injection
        crop_path = None
        try:
            if save_crop and unique_id is not None and item_index is not None:
                safe_label = re.sub(r"[^a-zA-Z0-9_-]+", "_", str(label))[:40]
                crop_filename = f"crop_{unique_id}_{int(item_index):02d}_{safe_label}.png"
                crop_path = os.path.join("outputs", crop_filename)
                cropped_img.save(crop_path, "PNG")
        except Exception:
            crop_path = None

        prompt = (
            f"Analyze this image cutout of a '{label}'.\n"
            "IMPORTANT: Look specifically at the TEXT written below or near the object.\n"
            "1. **READ EXTRACT DIMENSIONS:** If there is text like 'W: 2800', 'Width 2800mm', '2800*1450', extract these numbers EXACTLY in millimeters.\n"
            "2. Describe: Material, Color, Shape.\n"
            "\n"
            "Return STRICT JSON only:\n"
            "{\n"
            "  \"description\": \"Visual description...\",\n"
            "  \"dimensions_mm\": {\"width\": int/null, \"depth\": int/null, \"height\": int/null},\n"
            "  \"raw_text_found\": \"copy the text you read here\"\n"
            "}\n"
        )
        
        response = call_gemini_with_failover(ANALYSIS_MODEL_NAME, [prompt, cropped_img], {'timeout': 30}, {})
        
        desc = f"A high quality {label}."
        dims_str = ""
        
        if response and response.text:
            data = _safe_extract_json(response.text)
            if data:
                desc = data.get("description", desc)
                raw_dims = data.get("dimensions_mm", {})
                
                # ê°•ì œë¡œ descriptionì— ì¹˜ìˆ˜ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°•ì•„ë„£ìŒ (íŒŒì‹± ë¡œì§ì´ ì½ì„ ìˆ˜ ìˆê²Œ)
                w = raw_dims.get("width")
                d = raw_dims.get("depth")
                h = raw_dims.get("height")
                
                if w or d or h:
                    dims_str = f" Dimensions: W={w}mm, D={d}mm, H={h}mm."
                    # ë¡œê¹…
                    print(f"   -> [Text Read] {label}: {dims_str} (Source: {data.get('raw_text_found')})", flush=True)
                
        if cropped_img:
            try:
                cropped_img.close()
            except Exception:
                pass
        return {
            "label": label,
            "description": desc + dims_str, # ì¹˜ìˆ˜ ì •ë³´ë¥¼ ì„¤ëª…ì— ë³‘í•©
            "box_2d": box,
            "crop_path": crop_path,
        }
            
    except Exception as e:
        print(f"!! Crop Analysis Failed for {item_data.get('label','Furniture')}: {e}", flush=True)
        if cropped_img:
            try:
                cropped_img.close()
            except Exception:
                pass
    
    return {
        "label": item_data.get('label', 'Furniture'),
        "description": f"A high quality {item_data.get('label','Furniture')}.",
        "box_2d": item_data.get('box_2d'),
        "crop_path": None,
    }

# [ìµœì¢… ë³µêµ¬ ë° ì—…ê·¸ë ˆì´ë“œ] ë¶„ì„(Flash) -> ìƒì„±(Pro-Image) 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
# êµ¬ê¸€ AI ìŠ¤íŠœë””ì˜¤ì˜ "Generative Reconstruction" ë¡œì§ ì´ì‹
def generate_frontal_room_from_photos(photo_paths, unique_id, index):
    input_images = []
    try:
        print(f"   [Frontal Gen] Step 1: Analyzing {len(photo_paths)} photos with Flash (Spatial Mapping)...", flush=True)
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        for path in photo_paths:
            try:
                with Image.open(path) as img:
                    img.thumbnail((1536, 1536))
                    input_images.append(img.copy())
            except: pass

        if not input_images:
            return None

        # ---------------------------------------------------------
        # [Step 1] Flash ëª¨ë¸ë¡œ "ê³µê°„ êµ¬ì¡° ë° 3D ë§¤í•‘" ë¶„ì„
        # AI ìŠ¤íŠœë””ì˜¤ì˜ "Comprehending Spatial Data" ë‹¨ê³„ë¥¼ ìˆ˜í–‰
        # ---------------------------------------------------------
        analysis_prompt = (
            "You are a Spatial Architect AI. Analyze these multiple photos of the SAME room taken from different angles.\n"
            "Your goal is to build a mental 3D model of this space to reconstruct a 'Perfect Frontal View'.\n\n"
            "OUTPUT THE FOLLOWING SPATIAL BLUEPRINT:\n"
            "1. **Anchor Elements:** Identify fixed structures (e.g., 'Large window on far wall', 'Black wall on left', 'Pillar on right').\n"
            "2. **Geometry & Materials:** Describe the ceiling (e.g., recessed, lighting type) and floor (e.g., tile reflection, pattern) in detail.\n"
            "3. **Symmetry Plan:** If we place a camera in the exact center of the room facing the main window, describe what should be seen on the Left, Center, and Right to achieve perfect symmetry.\n"
            "Output ONLY the spatial blueprint description."
        )
        
        # ë¶„ì„ ëª¨ë¸ í˜¸ì¶œ
        analysis_res = call_gemini_with_failover(ANALYSIS_MODEL_NAME, [analysis_prompt] + input_images, {'timeout': 45}, {})
        spatial_blueprint = analysis_res.text if (analysis_res and analysis_res.text) else "A modern living room with large windows and tiled floor."
        
        print(f"   [Frontal Gen] Step 2: Synthesizing Frontal View based on Spatial Blueprint...", flush=True)

        # ---------------------------------------------------------
        # [Step 2] Pro Image ëª¨ë¸ë¡œ "ìƒì„±í˜• ì¬êµ¬ì„±(Generative Reconstruction)"
        # AI ìŠ¤íŠœë””ì˜¤ì˜ "Defining the Frontal View" & "Spatial Fidelity" ë¡œì§ ì´ì‹
        # ---------------------------------------------------------
        generation_prompt = (
            f"TASK: Generative Space Reconstruction (Multi-View to Single Frontal View).\n"
            f"ACT AS: High-end Architectural Photographer.\n\n"
            
            f"<SPATIAL BLUEPRINT (SOURCE TRUTH)>\n"
            f"{spatial_blueprint}\n"
            f"--------------------------------------------------\n\n"
            
            "VIRTUAL CAMERA SETUP:\n"
            "- **Position:** Place the virtual camera in the DEAD CENTER of the room.\n"
            "- **Target:** Face strictly forward towards the main focal point (usually the window).\n"
            "- **Lens:** 10mm Wide-Angle Rectilinear Lens (Capture the full width, NO fish-eye distortion).\n"
            "- **Height:** Eye-level (approx 130cm).\n\n"
            
            "COMPOSITION RULES (STRICT SYMMETRY):\n"
            "1. **Reconstruct the Space:** Synthesize a single, coherent 1-point perspective view using features from ALL input images.\n"
            "2. **Alignment:** Vertical lines (pillars, window frames) must be perfectly vertical. Horizontal lines (floor/ceiling) must converge to a single center vanishing point.\n"
            "3. **Consistency:** Ensure the 'Black Wall' (if present) and 'Pillars' are placed correctly relative to the center view as defined in the blueprint.\n\n"
            
            "LIGHTING & FIDELITY:\n"
            "- **Reflections:** Render accurate reflections on the floor tiles matching the ceiling lights.\n"
            "- **Lighting:** Uniform, bright, high-end interior lighting. No dark corners.\n"
            "- **Resolution:** 8k, extremely sharp, photorealistic.\n\n"
            
            "NEGATIVE CONSTRAINTS:\n"
            "- Do NOT produce a collage or grid. Output ONE single image.\n"
            "- No text, watermarks, blurred textures, or distorted geometry.\n"
            "- Do not simply crop one image; SYNTHESIZE the complete view."
            "- **Zoomed in, Close-up, Cropped views.** (CRITICAL FAIL)\n"
            "- **DO NOT include text, watermark, username, interface, subtitle.**\n"
            "- Distorted pillars, curved horizon, fisheye curvature."
        )

        # ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ í˜¸ì¶œ
        # input_imagesë¥¼ í•¨ê»˜ ë„£ì–´ì£¼ì–´ ì‹œê°ì  í…ìŠ¤ì²˜(Texture)ë¥¼ ì°¸ì¡°í•˜ê²Œ í•¨
        content_list = [generation_prompt] + input_images
        
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }

        response = call_gemini_with_failover(MODEL_NAME, content_list, {'timeout': 100}, safety_settings)

        if response and hasattr(response, 'candidates') and response.candidates:
            for part in response.parts:
                if hasattr(part, 'inline_data'):
                    timestamp = int(time.time())
                    out_filename = f"frontal_view_{timestamp}_{unique_id}_{index}.png"
                    out_path = os.path.join("outputs", out_filename)
                    with open(out_path, 'wb') as f: f.write(part.inline_data.data)
                    
                    # [ìœ ì§€] í‘œì¤€í™” í•¨ìˆ˜ (ì—ëŸ¬ ì—†ì´ í˜¸ì¶œ)
                    final_path = standardize_image(out_path)
                    return f"/outputs/{os.path.basename(final_path)}"
        return None

    except Exception as e:
        print(f"!! Frontal Gen Error: {e}", flush=True)
        return None
    finally:
        for im in input_images:
            try:
                im.close()
            except Exception:
                pass

# [ìˆ˜ì •] ì´ë¯¸ì§€ í¸ì§‘/ë°ì½”ë ˆì´ì…˜ ì²˜ë¦¬ ë¡œì§ (Inpainting & Resizing ê°•í™” ë²„ì „)
def process_image_edit_logic(photo_paths, instructions, mode, unique_id, index):
    try:
        print(f"   [{mode.upper()}] Processing step with instructions: {instructions}", flush=True)
        
        if not photo_paths: return None
        target_path = photo_paths[0] 
        img = None
        
        try:
            with Image.open(target_path) as base_img:
                base_img.thumbnail((2048, 2048))
                img = base_img.copy()
        except: return None

        # ëª¨ë“œë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
        if mode == 'edit':
            # [EDIT MODE] - Inpainting & Regeneration Focus
            role = "Expert AI Inpainter & Scene Reconstructor."
            task = "Your goal is to MODIFY the scene by ERASING existing objects and REDRAWING them according to the user's size/position requests."
            
            critical_rule = (
                "1. **DESTRUCTIVE EDITING (CRITICAL):** If the user asks to make an object SMALLER, do NOT just shrink it. You MUST **ERASE** the original large object and **REDRAW** a completely new, smaller version in its place.\n"
                "2. **BACKGROUND HALLUCINATION:** When you shrink an object, the wall and floor behind it will be exposed. You MUST **INPAINT** (generate) this missing background texture (wallpaper, skirting board, flooring) seamlessly. Do NOT leave artifacts or the ghost of the old object.\n"
                "3. **AGGRESSIVE SCALE CHANGE:** If the user says 'shrink by 50%' or 'make it small', the new object MUST be visually TINY compared to the original. Do not be subtle. Make the change DRASTIC.\n"
                "4. **ISOLATION:** Ensure the modified object does NOT touch the edges of the room if it's meant to be freestanding. Add empty space on both sides.\n"
                "5. **COLOR/MATERIAL:** Overwrite pixel colors completely if a color change is requested."
            )
            
            # ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ì— 'ì¤„ì—¬'ë‚˜ 'shrink', 'smaller'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê°•ì œë¡œ ê°•ì¡° ë¬¸êµ¬ ì¶”ê°€
            inst_lower = instructions.lower()
            if any(x in inst_lower for x in ['ì¤„ì—¬', 'ì‘ê²Œ', 'shrink', 'small', 'reduce', 'tiny']):
                instructions += " (IMPORTANT: The object MUST become significantly smaller. REVEAL the wall/floor behind it.)"

        else:
            # [DECORATE MODE] - ê¸°ì¡´ ìœ ì§€
            role = "Expert Home Stager."
            task = "Add decorations and props to the EXISTING room without changing furniture layout."
            critical_rule = (
                "1. **ADDITIVE ONLY:** Do NOT move or remove existing large furniture.\n"
                "2. **PROPS:** Add items like plants, cushions, rugs, lamps, books as requested.\n"
                "3. **STYLE:** Match the lighting and shadow of the original photo perfectly."
            )

        prompt = (
            f"ACT AS: {role}\n"
            f"TASK: {task}\n\n"
            
            f"<USER INSTRUCTIONS (EXECUTE AGGRESSIVELY)>\n"
            f"\"{instructions}\"\n"
            f"--------------------------------------------------\n\n"
            
            f"<CRITICAL RULES>\n"
            f"{critical_rule}\n"
            "4. **OUTPUT:** Return a single, high-quality photorealistic image.\n"
            "5. **NO TEXT:** Do not add watermarks or text."
        )

        # ëª¨ë¸ í˜¸ì¶œ (ì˜¨ë„ë¥¼ ì‚´ì§ ë†’ì—¬ì„œ ë³€í™”ë¥¼ ìœ ë„)
        response = call_gemini_with_failover(MODEL_NAME, [prompt, img], {'timeout': 90}, {})

        if response and hasattr(response, 'candidates') and response.candidates:
            for part in response.parts:
                if hasattr(part, 'inline_data'):
                    timestamp = int(time.time())
                    out_filename = f"{mode}_{timestamp}_{unique_id}_{index}.png"
                    out_path = os.path.join("outputs", out_filename)
                    with open(out_path, 'wb') as f: f.write(part.inline_data.data)
                    
                    # í•´ìƒë„/ë¹„ìœ¨ ë³µêµ¬
                    final_path = standardize_image_to_reference_canvas(out_path, target_path)
                    try:
                        if img:
                            img.close()
                    except Exception:
                        pass
                    return f"/outputs/{os.path.basename(final_path)}"
        try:
            if img:
                img.close()
        except Exception:
            pass
        return None

    except Exception as e:
        print(f"!! {mode} Gen Error: {e}", flush=True)
        try:
            if img:
                img.close()
        except Exception:
            pass
        return None

# [NEW] ì—”ë“œí¬ì¸íŠ¸: ë„ë©´ ì—…ë¡œë“œ ëŒ€ì‹  -> ê·¸ëƒ¥ ì‚¬ì§„ë“¤ë§Œ ì—…ë¡œë“œ
@app.post("/generate-frontal-view")
def generate_frontal_view_endpoint(
    input_photos: List[UploadFile] = File(...) 
):
    try:
        unique_id = uuid.uuid4().hex[:8]
        timestamp = int(time.time())
        print(f"\n=== [Frontal View Gen] Processing {len(input_photos)} photos ===", flush=True)

        # 1. ì—…ë¡œë“œëœ ì‚¬ì§„ë“¤ ì €ì¥
        saved_photo_paths = []
        for idx, photo in enumerate(input_photos):
            # íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            safe_name = "".join([c for c in photo.filename if c.isalnum() or c in "._-"])
            path = os.path.join("outputs", f"src_{timestamp}_{unique_id}_{idx}_{safe_name}")
            
            with open(path, "wb") as buffer: 
                shutil.copyfileobj(photo.file, buffer)
            saved_photo_paths.append(path)
        
        generated_results = []
        
        # 2. ë³‘ë ¬ ìƒì„± (5ì¥ ì‹œë„)
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(generate_frontal_room_from_photos, saved_photo_paths, unique_id, i+1) for i in range(3)]
            for future in futures:
                res = future.result()
                if res: generated_results.append(res)
        
        if generated_results:
            return JSONResponse(content={"urls": generated_results, "message": "Success"})
        else:
            return JSONResponse(content={"error": "Failed to generate images"}, status_code=500)
            
    except Exception as e:
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [Error] {e}")
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)

# [NEW] í¸ì§‘/ë°ì½”ë ˆì´ì…˜ ì „ìš© ì—”ë“œí¬ì¸íŠ¸
@app.post("/generate-image-edit")
def generate_image_edit_endpoint(
    input_photos: List[UploadFile] = File(...),
    instructions: str = Form(...),
    mode: str = Form(...)  # 'edit' or 'decorate'
):
    try:
        unique_id = uuid.uuid4().hex[:8]
        timestamp = int(time.time())
        print(f"\n=== [Image {mode.upper()}] Request: {instructions} ===", flush=True)

        # 1. ì‚¬ì§„ ì €ì¥
        saved_photo_paths = []
        for idx, photo in enumerate(input_photos):
            safe_name = "".join([c for c in photo.filename if c.isalnum() or c in "._-"])
            path = os.path.join("outputs", f"src_{mode}_{timestamp}_{unique_id}_{idx}_{safe_name}")
            with open(path, "wb") as buffer: 
                shutil.copyfileobj(photo.file, buffer)
            saved_photo_paths.append(path)
        
        generated_results = []
        
        # 2. ìƒì„± (ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬)
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(process_image_edit_logic, saved_photo_paths, instructions, mode, unique_id, i+1) for i in range(1)]
            for future in futures:
                res = future.result()
                if res: generated_results.append(res)
        
        if generated_results:
            return JSONResponse(content={"urls": generated_results, "message": "Success"})
        else:
            return JSONResponse(content={"error": "Failed to generate image"}, status_code=500)
            
    except Exception as e:
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [Error] {e}")
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)
# -----------------------------------------------------------------------------
# Generation Logic
# -----------------------------------------------------------------------------

def generate_empty_room(image_path, unique_id, start_time, stage_name="Stage 1"):
    if time.time() - start_time > TOTAL_TIMEOUT_LIMIT: return image_path
    print(f"\n--- [{stage_name}] ë¹ˆ ë°© ìƒì„± ì‹œì‘ ({MODEL_NAME}) ---", flush=True)
    
    img = Image.open(image_path)
    system_instruction = "You are an expert architectural AI."
    
    prompt = (
        "IMAGE EDITING TASK: Extreme Cleaning & Architectural Restoration.\n\n"        
        "<CRITICAL: STRUCTURAL PRESERVATION (PRIORITY #0)>\n"
        "1. **DO NOT REMOVE FIXTURES:** You must strictly PRESERVE all structural elements including Columns, Pillars, Beams, Windows (frames & glass), Doors, and Built-in fireplaces.\n"
        "2. **ONLY REMOVE MOVABLES:** Only remove furniture, rugs, lightings,curtains, and decorations that are NOT part of the building structure.\n"
        "3. **VIEW PROTECTION:** Keep the view outside the window 100% original.\n\n"
        
        "<CRITICAL: COMPLETE ERADICATION (PRIORITY #1)>\n"
        "1. REMOVE EVERYTHING ELSE: Identify and remove ALL movable furniture, rugs, curtains, lightings, wall decor, and small objects.\n"
        "2. CLEAN SURFACES: The floor and walls must be perfectly empty. Remove all shadows, reflections, and traces.\n"
        "3. BARE SHELL: Restore the room to its initial construction state.\n\n"
        
        "OUTPUT RULE: Return a perfectly clean, empty architectural shell with all structural pillars and windows intact."
    )
    
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    for try_count in range(3):
        remaining = max(10, TOTAL_TIMEOUT_LIMIT - (time.time() - start_time))
        response = call_gemini_with_failover(MODEL_NAME, [prompt, img], {'timeout': remaining}, safety_settings, system_instruction)
        
        if response and hasattr(response, 'candidates') and response.candidates:
            if hasattr(response, 'parts') and response.parts:
                for part in response.parts:
                    if hasattr(part, 'inline_data'):
                        print(f">> [ì„±ê³µ] ë¹ˆ ë°© ì´ë¯¸ì§€ ìƒì„±ë¨! ({try_count+1}íšŒì°¨)", flush=True)
                        timestamp = int(time.time())
                        filename = f"empty_{timestamp}_{unique_id}.png"
                        path = os.path.join("outputs", filename)
                        with open(path, 'wb') as f: f.write(part.inline_data.data)
                        # [FIX] Stage 1 ê²°ê³¼ë„ ì…ë ¥ ìº”ë²„ìŠ¤(ì›ë³¸ ë°© ì‚¬ì§„) ë¹„ìœ¨/í•´ìƒë„ë¡œ ê°•ì œ í†µì¼
                        try:
                            img.close()
                        except Exception:
                            pass
                        return standardize_image_to_reference_canvas(path, image_path)
            else:
                print(f"âš ï¸ [Blocked] ì•ˆì „ í•„í„° ì°¨ë‹¨", flush=True)
        print(f"âš ï¸ [Retry] ì‹œë„ {try_count+1} ì‹¤íŒ¨. ì¬ì‹œë„...", flush=True)

    print(">> [ì‹¤íŒ¨] ë¹ˆ ë°© ìƒì„± ë¶ˆê°€. ì›ë³¸ ì‚¬ìš©.", flush=True)
    try:
        img.close()
    except Exception:
        pass
    return image_path

# [ìˆ˜ì •] ì›ë³¸ í”„ë¡¬í”„íŠ¸ ìœ ì§€ + ë¹„ìœ¨ ìë™ ê°ì§€ + í…ìŠ¤íŠ¸/ì—¬ë°± ê¸ˆì§€ + ë¬´ë“œë³´ë“œ ë¹„ìœ¨ ë¬´ì‹œ + ê³µê°„ ì œì•½ ì‚¬í•­ ì¶”ê°€
def generate_furnished_room(
    room_path,
    style_prompt,
    ref_path,
    unique_id,
    furniture_specs=None,
    furniture_specs_json=None,
    room_dimensions=None,
    placement_instructions=None,
    scale_guide_path=None,
    primary_item=None,
    room_dims_parsed=None,
    wall_span_norm=None,
    size_hierarchy=None,
    start_time=0,
):
    if time.time() - start_time > TOTAL_TIMEOUT_LIMIT: return None
    room_img = None
    extra_imgs = []
    try:
        room_img = Image.open(room_path)
        
        # [NEW] ì´ë¯¸ì§€ ë¹„ìœ¨ ê³„ì‚° (ê°€ë¡œí˜•/ì„¸ë¡œí˜• íŒë‹¨)
        width, height = room_img.size
        is_portrait = height > width
        ratio_instruction = "PORTRAIT (4:5 Ratio)" if is_portrait else "LANDSCAPE (16:9 Ratio)"
        
        system_instruction = "You are an expert interior designer AI."
        
        specs_context = ""
        if furniture_specs:
            specs_context = (
                "\n<REFERENCE MATERIAL PALETTE (READ ONLY)>\n"
                "The following list describes the MATERIALS and COLORS.\n"
                "**WARNING:** Do NOT copy the text/dimensions/layout from the reference. Use ONLY materials.\n"
                f"{furniture_specs}\n"
                "--------------------------------------------------\n"
            )

        # [A-Variant] Add a strict dimension table (mm) for ALL items when available.
        dims_table_context = ""
        try:
            if furniture_specs_json and isinstance(furniture_specs_json, dict):
                rows = []
                for it in (furniture_specs_json.get("items") or []):
                    lbl = (it.get("label") or "").strip()
                    dm = it.get("dims_mm") or {}
                    w = dm.get("width_mm"); d = dm.get("depth_mm"); h = dm.get("height_mm")
                    if any([w, d, h]):
                        rows.append(f"- {lbl}: W={w or 'null'}mm, D={d or 'null'}mm, H={h or 'null'}mm")
                if rows:
                    dims_table_context = (
                        "\n<FURNITURE DIMENSIONS TABLE (MM) - STRICT>\n"
                        "Use these real-world measurements. Do NOT invent new sizes.\n"
                        + "\n".join(rows) + "\n"
                        "Hard constraints:\n"
                        "- No furniture item may exceed room width or room depth.\n"
                        "- Rugs/carpets: if rug width is within 10% of room width, it must visually span almost wall-to-wall.\n"
                        "- Wall storage/sideboard: if width is <= 1500mm in specs, it must NOT look like it spans most of the wall.\n"
                        "--------------------------------------------------\n"
                    )
        except Exception:
            dims_table_context = ""

        # [NEW] ê³µê°„ ì œì•½ ì‚¬í•­ ë° SCALE FIX ê³„ì‚° ë¡œì§ ê°•í™”
        spatial_context = ""
        calculated_analysis = ""
        relative_ratio_prompt = "" # [NEW] ê°€êµ¬ ê°„ ë¹„ìœ¨ í”„ë¡¬í”„íŠ¸
        
        try:
            _room_dims = room_dims_parsed or parse_room_dimensions_mm(room_dimensions or "")
            room_w = int(_room_dims.get("width_mm") or 0)
            room_d = int(_room_dims.get("depth_mm") or 0)

            _primary = primary_item or (furniture_specs_json or {}).get("primary") or {}
            _p_dims = _primary.get("dims_mm") or {}
            p_w = int(_p_dims.get("width_mm") or 0)
            
            # Primary Width Fallback from max_width if missing
            if not p_w and furniture_specs_json and isinstance(furniture_specs_json, dict):
                try: p_w = int(furniture_specs_json.get("max_width_mm") or 0)
                except: pass
            
            p_d = int(_p_dims.get("depth_mm") or 0)

            # ------------------------------------------------------------------
            # [NEW] RELATIVE SCALE CALCULATION (ê°€êµ¬ ëŒ€ ê°€êµ¬ ë¹„ë¡€ ê°•ì œ)
            # "StorageëŠ” Sofaì˜ 53% ë„ˆë¹„ì—¬ì•¼ í•œë‹¤" ê°™ì€ êµ¬ì²´ì  ë¹„ìœ¨ì„ ê³„ì‚°
            # ------------------------------------------------------------------
            if p_w > 0 and furniture_specs_json:
                ratio_lines = []
                primary_label = _primary.get('label', 'Primary Furniture')
                
                for it in (furniture_specs_json.get("items") or []):
                    # ìê¸° ìì‹ ì´ë‚˜ ëŸ¬ê·¸ëŠ” ì œì™¸
                    if it.get("label") == primary_label or it.get("is_rug"): continue
                    
                    sub_w = int((it.get("dims_mm") or {}).get("width_mm") or 0)
                    if sub_w > 0:
                        # ë¹„ìœ¨ ê³„ì‚° (ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€)
                        ratio_pct = round((sub_w / p_w) * 100, 1)
                        ratio_lines.append(f"- **{it.get('label')}** width must be approx **{ratio_pct}%** of the {primary_label}.")
                
                if ratio_lines:
                    relative_ratio_prompt = (
                        "\n<CRITICAL: RELATIVE PROPORTIONS (FURNITURE vs FURNITURE)>\n"
                        f"You must respect the size ratio between the '{primary_label}' and other items.\n"
                        "Do NOT enlarge secondary items to fill space. Keep them proportionally smaller.\n"
                        + "\n".join(ratio_lines) + "\n"
                        "--------------------------------------------------\n"
                    )
            # ------------------------------------------------------------------

            if room_w > 0 and p_w > 0:
                occ = round((p_w / room_w) * 100, 1)
                
                # [CRITICAL] ë‚¨ì€ ì—¬ë°± ê³„ì‚° (ì–‘ìª½ í•©ê³„)
                gap_total_mm = room_w - p_w
                gap_side_mm = int(gap_total_mm / 2) if gap_total_mm > 0 else 0
                
                calculated_analysis += f"   - **PRIMARY ANCHOR:** {_primary.get('label','Primary Furniture')} (Width {p_w}mm)\n"
                calculated_analysis += f"   - **ROOM WIDTH:** {room_w}mm\n"
                calculated_analysis += f"   - **CALCULATED GAP:** Total empty space width = {gap_total_mm}mm. (approx {gap_side_mm}mm on each side).\n"
                calculated_analysis += f"   - **WIDTH OCCUPANCY:** {occ}% (The furniture takes up {occ}% of the wall).\n"

                if occ > 92:
                    calculated_analysis += "   - **ACTION: WALL-TO-WALL FIT.** The furniture is almost as wide as the room. It must TOUCH the side walls or have negligible gaps.\n"
                elif occ > 80:
                    calculated_analysis += "   - **ACTION: TIGHT FIT.** The furniture dominates the wall. Leave only SMALL gaps on the sides.\n"
                else:
                    calculated_analysis += "   - **ACTION: STANDARD FIT.** Center the furniture with visible breathing room on sides.\n"
            else:
                calculated_analysis += "   - (No reliable mm dimensions found; apply relative scaling from reference hierarchy)\n"
                
        except Exception:
            pass

        if room_dimensions or placement_instructions:
            spatial_context = "\n<PHYSICAL SPACE CONSTRAINTS (STRICT ADHERENCE)>\n"
            if room_dimensions:
                spatial_context += f"- **ACTUAL ROOM DIMENSIONS:** {room_dimensions}\n"
            if placement_instructions:
                spatial_context += f"- **PLACEMENT INSTRUCTIONS:** {placement_instructions}\n"
            spatial_context += (
                "**SCALING RULE:** You MUST calibrate the scale of all furniture relative to the ACTUAL ROOM DIMENSIONS provided.\n"
                f"{calculated_analysis}\n" # ê³„ì‚°ëœ ë¶„ì„ ê²°ê³¼ ì‚½ì…
                "Do NOT shrink furniture to create artificial empty space. If the room is small, it should look appropriately filled.\n"
                "--------------------------------------------------\n"
            )

        # [NEW] hierarchy hint string
        size_hierarchy_hint = ""
        try:
            if size_hierarchy and isinstance(size_hierarchy, list):
                size_hierarchy_hint = " > ".join([str(x) for x in size_hierarchy if x])
            elif furniture_specs_json and isinstance(furniture_specs_json, dict):
                h = furniture_specs_json.get("size_hierarchy") or []
                if isinstance(h, list):
                    size_hierarchy_hint = " > ".join([str(x) for x in h if x])
        except Exception:
            size_hierarchy_hint = ""


        user_original_prompt = (
            "IMAGE MANIPULATION TASK (Virtual Staging - Overlay Only):\n"
            "Your goal is to PLACE furniture into the EXISTING empty room image without changing the room itself.\n\n"
            
            "<CRITICAL: ARCHITECTURAL FREEZE (PRIORITY #1)>\n"
            "1. **DO NOT RE-GENERATE THE ROOM:** The walls, ceiling, floor pattern, window size, and view outside the window must remain 100% IDENTICAL to the input image.\n"
            "2. **PERSPECTIVE LOCK:** You must use the EXACT same camera angle and perspective. Do not zoom in, do not zoom out.\n"
            "3. **DEPTH PRESERVATION:** Do not expand the room. Keep the original spatial depth.\n\n"
            
            "<CRITICAL: FURNITURE COMPOSITING>\n"
            "1. **SCALE:** Fit furniture realistically within the *existing* floor space.\n"
            "2. **PLACEMENT:** Place items *on* the floor. Ensure legs touch the ground with correct contact shadows.\n"
            "3. **STYLE:** Match the Reference Moodboard style.\n"
            "4. **WINDOW TREATMENT (CURTAINS - LOCATION STRICT):** Add floor-to-ceiling **Sheer White Chiffon Curtains**. <CRITICAL>: Place them **ONLY** along the vertical edges of the GLASS WINDOW. **DO NOT** generate curtains on solid walls, corners without windows, or doors. They must **HANG STRAIGHT DOWN NATURALLY** (do not tie) covering only the outer 15% of the glass to frame the view.\n\n"

            "<CRITICAL: MATHEMATICAL SCALE ENFORCEMENT (PRIORITY #0)>\nYou are provided with ACTUAL DIMENSIONS, PRIMARY ANCHOR, and (optionally) a SCALE GUIDE IMAGE. Do not ignore them.\nIMPORTANT: The 'PRIMARY ANCHOR' is the largest-volume movable furniture (EXCLUDING rugs/carpets).\nSIZE HIERARCHY (largest -> smallest, exclude rugs/carpets): {size_hierarchy_hint}\n\n"
            "You are provided with ACTUAL DIMENSIONS and PRE-CALCULATED RATIOS. Do not ignore them.\n"
            
            "1. **SPECIFIC SCALE ANALYSIS FOR THIS REQUEST:**\n"
            f"{calculated_analysis if calculated_analysis else '   - (Apply relative scaling based on provided specs)'}\n"
            
            "2. **RELATIVE HEIGHT HIERARCHY:**\n"
            "   - You MUST maintain the visual height hierarchy specified in the specs.\n"
            "   - Example: If Item A (Height: 950mm) is taller than Item B (Height: 775mm), Item A MUST be rendered taller than Item B in the image.\n"
            
            "3. **RATIO LOCK:**\n"
            "   - Calculate: (Furniture Depth / Room Depth) = Floor Space Coverage.\n"
            "   - Strictly follow these percentages. Do not shrink deep furniture into 'miniature' versions to create empty space.\n"
            "   - **STRICT PROHIBITION:** Do not resize items for 'vibe' or 'aesthetic balance'. Follow the NUMBERS strictly.\n\n"

            "<CRITICAL: WINDOW LIGHT MUST BE ABUNDANT (PRIORITY #1)>\n"
            "1. **ABUNDANT WINDOW LIGHT:** The scene MUST be strongly illuminated by abundant daylight coming from the window.\n"
            "2. **EXPOSURE RULE:** Bright and airy (not dark), while preserving highlight detail (no blown-out whites).\n"
            "3. **LIGHT DIRECTION:** Clearly visible light direction from the window; cast soft but present shadows across the floor.\n"
            "4. **NO DIM ROOM:** Do NOT generate a dim, underexposed, moody, or nighttime look.\n"
            "5. **WHITE BALANCE:** Neutral daylight white balance (around 4000~5000K). **NO warm/yellow cast.**\n\n"

        "<CRITICAL: PHOTOREALISTIC LIGHTING INTEGRATION (HYBRID: DAYLIGHT + ARTIFICIAL)>\n"
            "1. **MANDATORY LIGHTING STATE: ALL ON (NEUTRAL ONLY):**\n"
            "   - **ACTION:** TURN ON every lighting fixture in the scene (Pendants, Floor Lamps, Recessed Lights, LED Strips).\n"
            "   - **VISUALS:** Render a visible 'glow' or subtle 'light bloom' around the fixtures to prove they are active. This adds a luxurious touch.\n"
            
            "2. **LIGHTING HIERARCHY (KEY vs. FILL):**\n"
            "   - **KEY LIGHT (DOMINANT):** Natural Daylight from the window is still the PRIMARY source (approx. 70% intensity). It defines the main shadow direction.\n"
            "   - **FILL LIGHT (SECONDARY):** The interior lights act as 'Fill Lights' (approx. 30% intensity) to brighten dark corners and highlight furniture textures. They should NOT overpower the sunlight.\n"
            
            "3. **STRICT COLOR TEMPERATURE CONTROL (NO YELLOW):**\n"
            "   - **Target Temperature:** Use **Pure Neutral White (4000K-5000K)** for all artificial lights to match the daylight.\n"
            "   - **PROHIBITED:** Do NOT use Warm/Tungsten/Orange bulbs (2700K). Even though lights are ON, the room must remain fresh and clean. No vintage/sepia cast.\n"
            
            "4. **SHADOW PHYSICS:**\n"
            "   - Cast soft, directional shadows driven by the window light.\n"
            "   - Use the interior lights to slightly soften (lift) the deepest shadows, preventing high-contrast black spots.\n"
            
            "5. **ATMOSPHERE:**\n"
            "   - Combine 'Sun-filled Freshness' with 'High-end Illuminated Luxury'. Bright, airy, and fully detailed.\n"
            "   - **OUTPUT RULE:** Return the image with furniture added, perfectly blended with abundant daylight AND active neutral interior lighting.\n"
        )
        
        prompt = (
            "ACT AS: Professional Interior Photographer.\n"
            f"{specs_context}\n" 
            f"{dims_table_context}\n"
            f"{spatial_context}\n"
            f"{relative_ratio_prompt}\n" # [CRITICAL] ì—¬ê¸°ì— ìƒëŒ€ ë¹„ìœ¨ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            f"{user_original_prompt}\n\n"
            
            f"<CRITICAL: OUTPUT FORMAT ENFORCEMENT -> {ratio_instruction}>\n"
            "1. **FULL BLEED CANVAS:** The output image MUST fill the entire canvas from edge to edge. **NO WHITE BARS.** NO SPLIT SCREENS.\n"
            "2. **NO TEXT OVERLAY:** Do NOT write any dimensions, labels, or watermarks on the final image. It must be a clean photo.\n"
            "3. **ASPECT RATIO LOCK:** Keep the aspect ratio of the 'Empty Room' input. Do not crop the ceiling or floor.\n"
            "4. **IGNORE REFERENCE RATIO:** Even if the Style Reference (Moodboard) is vertical, you MUST output a " + ratio_instruction + " image. Do not mimic the moodboard's shape.\n"
            "5. **NO MULTI-PANEL OUTPUT:** Output must be ONE single staged room photograph only. Do NOT append catalog sheets, white inventory panels, split layouts, or include the reference image anywhere."
        )
        
        prompt = prompt.replace("{size_hierarchy_hint}", size_hierarchy_hint or "")

        content = [prompt, "Empty Room (Target Canvas - KEEP THIS):", room_img]

        # [A-Variant] Provide cropped furniture cutouts
        try:
            if furniture_specs_json and isinstance(furniture_specs_json, dict):
                cutouts = []
                for it in (furniture_specs_json.get("items") or []):
                    cp = it.get("crop_path")
                    lbl = (it.get("label") or "").strip()
                    if cp and os.path.exists(cp):
                        cutouts.append((lbl, cp))
                for lbl, cp in cutouts[:10]:
                    cutout_img = Image.open(cp)
                    extra_imgs.append(cutout_img)
                    content += [f"Furniture Cutout Reference (MUST MATCH EXACT DESIGN). Label: {lbl}", cutout_img]
        except Exception:
            pass

        try:
            if scale_guide_path and os.path.exists(scale_guide_path):
                guide_img = Image.open(scale_guide_path)
                extra_imgs.append(guide_img)
                content += ["SCALE GUIDE IMAGE (do NOT render the guide; use only for measurement):", guide_img]
        except Exception:
            pass
        if ref_path:
            try:
                ref = Image.open(ref_path)
                ref.thumbnail((2048, 2048))
                extra_imgs.append(ref)
                content.extend(["Style Reference (Furniture Palette ONLY):", ref])
            except: pass
        
        remaining = max(30, TOTAL_TIMEOUT_LIMIT - (time.time() - start_time))
        
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        response = call_gemini_with_failover(MODEL_NAME, content, {'timeout': remaining}, safety_settings, system_instruction)
        
        if response and hasattr(response, 'candidates') and response.candidates and hasattr(response, 'parts'):
            for part in response.parts:
                if hasattr(part, 'inline_data'):
                    timestamp = int(time.time())
                    filename = f"result_{timestamp}_{unique_id}.png"
                    path = os.path.join("outputs", filename)
                    with open(path, 'wb') as f: f.write(part.inline_data.data)
                    return standardize_image_to_reference_canvas(path, room_path)
        return None
    except Exception as e:
        print(f"!! Stage 2 ì—ëŸ¬: {e}", flush=True)
        return None
    finally:
        for im in extra_imgs:
            try:
                im.close()
            except Exception:
                pass
        try:
            if room_img:
                room_img.close()
        except Exception:
            pass

def call_magnific_api(image_path, unique_id, start_time):
    if time.time() - start_time > TOTAL_TIMEOUT_LIMIT: 
        return image_path
    
    print(f"\n--- [Stage 4] ì—…ìŠ¤ì¼€ì¼ë§ ì‹œë„ (Key: {MAGNIFIC_API_KEY[:5]}...) ---", flush=True)
    
    if not MAGNIFIC_API_KEY or "your_" in MAGNIFIC_API_KEY:
         print(">> [SKIP] API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ë°˜í™˜.", flush=True)
         return image_path
         
    try:
        with open(image_path, "rb") as f: 
            b64 = base64.b64encode(f.read()).decode('utf-8')
            
        payload = {
            "image": b64, 
            "scale_factor": "2x", 
            "optimized_for": "films_n_photography", 
            "engine": "automatic",
            "creativity": 1,
            "hdr": 0,
            "resemblance": 10,
            "fractality": 1,
            "prompt": (
                "Professional interior photography, architectural digest style, "
                "shot on Phase One XF IQ4, 100mm lens, ISO 100, f/8, "
                "natural white daylight coming from window, sharp shadows, "
                "hyper-realistic material textures, raw photo, 8k resolution, "
                "imperfect details. "
                "--no 3d render, cgi, painting, drawing, cartoon, anime, illustration, plastic look, oversaturated, watermark, text, blur, distorted."
            )
        }
        headers = {
            "x-freepik-api-key": MAGNIFIC_API_KEY, 
            "Content-Type": "application/json"
        }
        
        res = requests.post(MAGNIFIC_ENDPOINT, json=payload, headers=headers)
        
        if res.status_code != 200:
            print(f"!! [API ì˜¤ë¥˜] Status: {res.status_code}, Msg: {res.text}", flush=True)
            return image_path

        data = res.json()
        
        if "data" not in data:
            return image_path

        if "task_id" in data["data"]:
            task_id = data["data"]["task_id"]
            print(f">> ì‘ì—… ì˜ˆì•½ë¨ (ID: {task_id})...", end="", flush=True)
            
            while time.time() - start_time < TOTAL_TIMEOUT_LIMIT:
                time.sleep(2)
                print(".", end="", flush=True)
                
                check = requests.get(f"{MAGNIFIC_ENDPOINT}/{task_id}", headers=headers)
                if check.status_code == 200:
                    status_data = check.json().get("data", {})
                    status = status_data.get("status")
                    
                    if status == "COMPLETED":
                        print(" ì™„ë£Œ!", flush=True)
                        gen_list = status_data.get("generated", [])
                        if gen_list and len(gen_list) > 0:
                            return download_image(gen_list[0], unique_id) or image_path
                    elif status == "FAILED": 
                        print(f" ì‹¤íŒ¨.", flush=True)
                        return image_path
            return image_path

        elif "generated" in data.get("data", {}):
             gen_list = data["data"]["generated"]
             if gen_list and len(gen_list) > 0:
                 return download_image(gen_list[0], unique_id) or image_path
                 
        return image_path
        
    except Exception as e:
        return image_path

def download_image(url, unique_id):
    try:
        res = requests.get(url)
        if res.status_code == 200:
            timestamp = int(time.time())
            filename = f"magnific_{timestamp}_{unique_id}.png"
            path = os.path.join("outputs", filename)
            with open(path, "wb") as f: f.write(res.content)
            return standardize_image(path, keep_ratio=True)
        return None
    except: return None

@app.get("/")
async def read_index(): return FileResponse("static/index.html")

# [NEW] Image Studio Page Route
@app.get("/image-studio")
def image_studio_page():
    return FileResponse(os.path.join("static", "image_studio.html"))

# Video Studio (separate page)
@app.get("/video-studio")
def video_studio_page():
    # Standalone page so users can build videos from existing images without re-rendering
    return FileResponse(os.path.join("static", "video_studio.html"))

@app.get("/api/outputs/list")
def api_outputs_list(limit: int = 200):
    """List recently generated/uploaded images in /outputs for Video Studio selection."""
    limit = max(1, min(int(limit or 200), 500))
    out_dir = Path("outputs")
    out_dir.mkdir(parents=True, exist_ok=True)

    exts = {".png", ".jpg", ".jpeg", ".webp"}
    items = []
    for p in out_dir.rglob("*"):
        if p.is_file() and p.suffix.lower() in exts:
            st = p.stat()
            rel = p.relative_to(out_dir).as_posix()
            items.append({"filename": rel, "url": f"/outputs/{rel}", "mtime": st.st_mtime})

    items.sort(key=lambda x: x["mtime"], reverse=True)
    return {"items": items[:limit]}

@app.post("/api/outputs/upload")
async def api_outputs_upload(file: UploadFile = File(...)):
    """Upload an image to /outputs and return a URL usable by the video pipeline."""
    out_dir = Path("outputs")
    out_dir.mkdir(parents=True, exist_ok=True)

    orig = (file.filename or "upload.png").strip()
    # keep filename safe
    safe = re.sub(r"[^a-zA-Z0-9._-]+", "_", orig)
    stamp = int(time.time())
    uid = uuid.uuid4().hex[:8]
    filename = f"upload_{stamp}_{uid}_{safe}"
    out_path = out_dir / filename

    content = await file.read()
    with open(out_path, "wb") as f:
        f.write(content)

    return {"filename": filename, "url": f"/outputs/{filename}"}


@app.get("/favicon.ico", include_in_schema=False)
async def favicon(): return FileResponse("static/logo2.png")

@app.get("/room-types")
async def get_room_types(): return JSONResponse(content=list(ROOM_STYLES.keys()))

@app.get("/styles/{room_type}")
async def get_styles_for_room(room_type: str):
    styles = ROOM_STYLES.get(room_type, [])
    if "Customize" not in styles:
        styles = styles + ["Customize"]
    return JSONResponse(content=styles)

@app.get("/api/thumbnails/{room_name}/{style_name}")
def get_available_thumbnails(room_name: str, style_name: str):
    safe_room = room_name.lower().replace(" ", "")
    safe_style = style_name.lower().replace(" ", "-").replace("_", "-")
    prefix = f"{safe_room}_{safe_style}_"
    
    base_dir = "static/thumbnails"
    if not os.path.exists(base_dir): return []

    valid_items = [] # [ë³€ê²½] ë‹¨ìˆœ ìˆ«ì ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
    valid_exts = ('.png', '.jpg', '.jpeg', '.webp')

    try:
        for f in os.listdir(base_dir):
            f_lower = f.lower()
            if f_lower.startswith(prefix) and f_lower.endswith(valid_exts):
                try:
                    name_part = f_lower.replace(prefix, "")
                    num_part = os.path.splitext(name_part)[0]
                    if num_part.isdigit():
                        # [ë³€ê²½] ë²ˆí˜¸ì™€ 'ì‹¤ì œ íŒŒì¼ëª…'ì„ í•¨ê»˜ ì €ì¥
                        valid_items.append({"index": int(num_part), "file": f})
                except: continue
        
        # ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        valid_items.sort(key=lambda x: x["index"])
        return valid_items
    except Exception as e:
        print(f"Thumbnail Scan Error: {e}")
        return []

# --- ë©”ì¸ ë Œë”ë§ ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/render")
def render_room(
    file: UploadFile = File(...), 
    room: str = Form(...), 
    style: str = Form(...), 
    variant: str = Form(...),
    moodboard: UploadFile = File(None),
    dimensions: str = Form(""),
    placement: str = Form("")
):
    try:
        unique_id = uuid.uuid4().hex[:8]
        print(f"\n=== ìš”ì²­ ì‹œì‘ [{unique_id}] (Integrated Analysis Mode) ===", flush=True)
        start_time = time.time()
        
        timestamp = int(time.time())
        safe_name = "".join([c for c in file.filename if c.isalnum() or c in "._-"])
        raw_path = os.path.join("outputs", f"raw_{timestamp}_{unique_id}_{safe_name}")
        with open(raw_path, "wb") as buffer: shutil.copyfileobj(file.file, buffer)
        
        std_path = standardize_image(raw_path)
        step1_img = generate_empty_room(std_path, unique_id, start_time, stage_name="Stage 1: Intermediate Clean")

        # [SCALE FIX vB] Precompute room dimensions + back wall span (for scale lock & auto-pick)
        room_dims_parsed = parse_room_dimensions_mm(dimensions or "")
        wall_span_norm = detect_back_wall_span_norm(step1_img) if step1_img else (0.0, 1.0)

        furniture_specs_json = None
        primary_item = None
        scale_guide_path = None
        size_hierarchy = None
        
        ref_path = None
        mb_url = None

        if style != "Customize":
            safe_room = room.lower().replace(" ", "") 
            safe_style = style.lower().replace(" ", "-").replace("_", "-")
            
            # [ìˆ˜ì •] í´ë” ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ì°¾ê¸° ë¡œì§
            target_path = os.path.join("assets", safe_room, safe_style)
            assets_dir = None

            # 1. ì •í™•í•œ ê²½ë¡œê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if os.path.exists(target_path):
                assets_dir = target_path
            else:
                # 2. ì—†ìœ¼ë©´ ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  íƒìƒ‰ (assets í´ë” ì•ˆì„ ë’¤ì§)
                # ì˜ˆ: ì½”ë“œëŠ” 'livingroom'ì„ ì°¾ì§€ë§Œ í´ë”ëŠ” 'LivingRoom'ì´ì–´ë„ ì°¾ê²Œ í•¨
                root_assets = "assets"
                if os.path.exists(root_assets):
                    # Room ì°¾ê¸°
                    found_room = next((d for d in os.listdir(root_assets) if d.lower() == safe_room), None)
                    if found_room:
                        room_path = os.path.join(root_assets, found_room)
                        # Style ì°¾ê¸°
                        found_style = next((d for d in os.listdir(room_path) if d.lower() == safe_style), None)
                        if found_style:
                            assets_dir = os.path.join(room_path, found_style)

            # í´ë”ë¥¼ ì°¾ì•˜ìœ¼ë©´ íŒŒì¼ ê²€ìƒ‰ ì‹œì‘
            if assets_dir and os.path.exists(assets_dir):
                files = sorted(os.listdir(assets_dir))
                found = False
                import re 
                
                # íŒŒì¼ëª… ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ í”Œë˜ê·¸ re.IGNORECASE ì¶”ê°€)
                pattern = rf"(?:^|[^0-9]){re.escape(variant)}(?:[^0-9]|$)"
                
                # ì§€ì›í•  í™•ì¥ì
                valid_exts = ('.png', '.jpg', '.jpeg', '.webp')

                for f in files:
                    # í™•ì¥ì ì²´í¬ & ë²ˆí˜¸ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
                    if f.lower().endswith(valid_exts) and re.search(pattern, f, re.IGNORECASE):
                        ref_path = os.path.join(assets_dir, f)
                        # URL ê²½ë¡œ ìƒì„± ì‹œ ì—­ìŠ¬ë˜ì‹œ(\)ë¥¼ ìŠ¬ë˜ì‹œ(/)ë¡œ ë°”ê¿”ì•¼ ì›¹ì—ì„œ ì•ˆê¹¨ì§
                        mb_url = f"/assets/{os.path.basename(os.path.dirname(assets_dir))}/{os.path.basename(assets_dir)}/{f}"
                        found = True
                        break
                
                # ëª» ì°¾ì•˜ëŠ”ë° íŒŒì¼ì´ ìˆë‹¤ë©´ ì²«ë²ˆì§¸ íŒŒì¼ ì‚¬ìš© (í™•ì¥ì ë§ëŠ” ê²ƒ ì¤‘)
                if not found:
                    valid_files = [f for f in files if f.lower().endswith(valid_exts)]
                    if valid_files:
                        f = valid_files[0]
                        ref_path = os.path.join(assets_dir, f)
                        mb_url = f"/assets/{os.path.basename(os.path.dirname(assets_dir))}/{os.path.basename(assets_dir)}/{f}"
        
        if style == "Customize" and moodboard:
            mb_name = "".join([c for c in moodboard.filename if c.isalnum() or c in "._-"])
            mb_path = os.path.join("outputs", f"mb_{timestamp}_{unique_id}_{mb_name}")
            with open(mb_path, "wb") as buffer: shutil.copyfileobj(moodboard.file, buffer)
            ref_path = mb_path
            mb_url = f"/outputs/{os.path.basename(mb_path)}"

        furniture_specs_text = None
        full_analyzed_data = [] 

        if ref_path and os.path.exists(ref_path):
            print(f">> [Global Analysis] Analyzing furniture in {ref_path}...", flush=True)
            try:
                detected = detect_furniture_boxes(ref_path)
                
                print(f">> [Global Analysis] Parallel analyzing {len(detected)} items...", flush=True)
                with ThreadPoolExecutor(max_workers=30) as executor:
                    futures = [executor.submit(analyze_cropped_item, ref_path, item) for item in detected]
                    full_analyzed_data = [f.result() for f in futures]
                try:
                    if full_analyzed_data:
                        logger.info(f"[Analysis] items={len(full_analyzed_data)}")
                        for i, it in enumerate(full_analyzed_data[:30]):
                            dims = parse_object_dimensions_mm(it.get("description",""))
                            logger.info(
                                f"[Analysis] #{i} {it.get('label')} "
                                f"dims(mm) W={dims.get('width_mm')} D={dims.get('depth_mm')} H={dims.get('height_mm')} "
                                f"crop={it.get('crop_path')} "
                                f"desc={ (it.get('description','')[:120]).replace('\\n',' ') }"
                            )
                except Exception:
                    logger.exception("[Analysis] logging failed")
                
                specs_list = []
                for idx, item in enumerate(full_analyzed_data):
                    specs_list.append(f"{idx+1}. {item['label']}: {item['description']}")
                furniture_specs_text = "\n".join(specs_list)

                # [SCALE FIX vB] Build furniture JSON + select PRIMARY (largest volume, exclude rugs/carpets)
                try:
                    furniture_specs_json = build_furniture_specs_json(full_analyzed_data)
                    primary_item = (furniture_specs_json or {}).get("primary")
                    size_hierarchy = (furniture_specs_json or {}).get("size_hierarchy")

                    logger.info(f"[Scale] primary_item={ (primary_item or {}).get('label') }")
                    logger.info(f"[Scale] room_dims_parsed={room_dims_parsed} wall_span_norm={wall_span_norm}")

                    # Optional: scale guide image (only if both room width and primary width are available)
                    try:
                        room_w = int((room_dims_parsed or {}).get("width_mm") or 0)
                        p_w = int(((primary_item or {}).get("dims_mm") or {}).get("width_mm") or 0)

                        if not p_w and furniture_specs_json and isinstance(furniture_specs_json, dict):
                            try:
                                p_w = int(furniture_specs_json.get("max_width_mm") or 0)
                            except Exception:
                                pass

                        logger.info(f"[Scale] room_w={room_w}mm p_w={p_w}mm step1_img={step1_img}")

                        if room_w > 0 and p_w > 0 and step1_img:
                            ratio = p_w / room_w
                            guide_out = os.path.join("outputs", f"scale_guide_{unique_id}.png")
                            scale_guide_path = create_scale_guide_image(step1_img, wall_span_norm, ratio, guide_out)

                            if scale_guide_path and os.path.exists(scale_guide_path):
                                logger.info(f"[Scale] âœ… scale guide saved: {scale_guide_path} (ratio={ratio:.4f})")
                            else:
                                logger.warning(f"[Scale] âŒ scale guide create returned: {scale_guide_path}")
                        else:
                            logger.warning("[Scale] Skipped scale guide: missing room_w or p_w or step1_img")
                    except Exception as e:
                        logger.exception(f"[Scale] scale guide exception: {e}")

                except Exception as e:
                    logger.exception(f"[Scale] furniture JSON build failed: {e}")
                    furniture_specs_json = None
                    primary_item = None
                    scale_guide_path = None
                    size_hierarchy = None
                
                print(f">> [Global Analysis] Complete. Specs injected.", flush=True)
                
            except Exception as e:
                print(f"!! [Global Analysis Failed] {e}", flush=True)

        generated_results = []
        print(f"\nğŸš€ [Stage 2] 3ì¥ ë™ì‹œ ìƒì„± ì‹œì‘ (Specs Injection)!", flush=True)

        def process_one_variant(index):
            sub_id = f"{unique_id}_v{index+1}"
            try:
                current_style_prompt = STYLES.get(style, "Custom Moodboard Style")
                res = generate_furnished_room(step1_img, current_style_prompt, ref_path, sub_id, furniture_specs=furniture_specs_text, furniture_specs_json=furniture_specs_json, room_dimensions=dimensions, placement_instructions=placement, scale_guide_path=scale_guide_path, primary_item=primary_item, room_dims_parsed=room_dims_parsed, wall_span_norm=wall_span_norm, size_hierarchy=size_hierarchy, start_time=start_time)
                if res: return f"/outputs/{os.path.basename(res)}"
            except Exception as e: print(f"   âŒ [Variation {index+1}] ì—ëŸ¬: {e}", flush=True)
            return None

        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(process_one_variant, i) for i in range(3)]
            for future in futures:
                res = future.result()
                if res: generated_results.append(res)
                gc.collect()

        final_before_url = f"/outputs/{os.path.basename(step1_img)}"
        if not generated_results: generated_results.append(f"/outputs/{os.path.basename(step1_img)}")

        scale_guide_url = None
        try:
            if scale_guide_path and os.path.exists(scale_guide_path):
                scale_guide_url = f"/outputs/{os.path.basename(scale_guide_path)}"
        except Exception:
            pass

        return JSONResponse(content={
            "original_url": f"/outputs/{os.path.basename(std_path)}",
            "empty_room_url": final_before_url,
            "result_url": generated_results[0],
            "result_urls": generated_results,
            "moodboard_url": mb_url,
            "scale_guide_url": scale_guide_url,   # âœ… ì¶”ê°€
            "furniture_data": full_analyzed_data,
            "message": "Complete"
        })

    except Exception as e:
        print(f"\nğŸ”¥ğŸ”¥ğŸ”¥ [SERVER CRASH] {e}", flush=True)
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)

class UpscaleRequest(BaseModel): image_url: str

class FinalizeRequest(BaseModel):
    image_url: str

@app.post("/finalize-download")
def finalize_download(req: FinalizeRequest):
    try:
        unique_id = uuid.uuid4().hex[:6]
        start_time = time.time()
        print(f"\n=== [Finalize] Download Request for {req.image_url} ===", flush=True)

        filename = os.path.basename(req.image_url)
        local_path = os.path.join("outputs", filename)
        if not os.path.exists(local_path): 
            return JSONResponse(content={"error": "Original file not found"}, status_code=404)

        # [ì—…ê·¸ë ˆì´ë“œ]
        # 1) ê°€êµ¬ë°© ì—…ìŠ¤ì¼€ì¼ì„ ë¨¼ì € ì‹œì‘í•´ë‘ê³ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ),
        # 2) ê·¸ ë™ì•ˆ ë¹ˆë°© ìƒì„± -> ë¹ˆë°© ì—…ìŠ¤ì¼€ì¼ ì‹œì‘
        # => ì²´ê° ëŒ€ê¸°ì‹œê°„ì„ ì¤„ì…ë‹ˆë‹¤.
        final_empty_path = ""
        final_furnished_path = ""

        # ì—…ìŠ¤ì¼€ì¼ë§ë„ 5-workerë¡œ ë³‘ë ¬ ì²˜ë¦¬ (ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ì—¬ìœ )
        with ThreadPoolExecutor(max_workers=5) as executor:
            print(">> [Step 1] Upscaling Furnished in parallel...", flush=True)
            future_furnished = executor.submit(call_magnific_api, local_path, unique_id + "_upscale_furnished", start_time)

            print(">> [Step 2] Creating matched Empty Room...", flush=True)
            empty_room_path = generate_empty_room(local_path, unique_id + "_final_empty", start_time, stage_name="Finalize: Empty Gen")

            print(">> [Step 3] Upscaling Empty Room...", flush=True)
            future_empty = executor.submit(call_magnific_api, empty_room_path, unique_id + "_upscale_empty", start_time)

            # ê²°ê³¼ ëŒ€ê¸°
            final_furnished_path = future_furnished.result()
            final_empty_path = future_empty.result()

        return JSONResponse(content={
            "upscaled_furnished": f"/outputs/{os.path.basename(final_furnished_path)}",
            "upscaled_empty": f"/outputs/{os.path.basename(final_empty_path)}",
            "message": "Success"
        })

    except Exception as e:
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [Finalize Error] {e}")
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)

@app.post("/upscale")
def upscale_and_download(req: UpscaleRequest):
    try:
        filename = os.path.basename(req.image_url)
        local_path = os.path.join("outputs", filename)
        if not os.path.exists(local_path): return JSONResponse(content={"error": "File not found"}, status_code=404)
        final_path = call_magnific_api(local_path, uuid.uuid4().hex[:8], time.time())
        return JSONResponse(content={"upscaled_url": f"/outputs/{os.path.basename(final_path)}", "message": "Success"})
    except Exception as e: return JSONResponse(content={"error": str(e)}, status_code=500)

def construct_dynamic_styles(analyzed_items):
    styles = []
    styles.append({
        "name": "High Angle Overview", 
        "prompt": (
            "CAMERA POSITION: High-angle view looking down from the ceiling.\n"
            "SUBJECT: The entire room layout exactly as shown in the original image.\n"
        ), 
        "ratio": "16:9"
    })
    # [ìˆ˜ì • 1] ì¢Œì¸¡ ê³µê°„ ê°•ì¡° (ì¹´ë©”ë¼ ì´ë™ X, í”„ë ˆì„ ì§‘ì¤‘ O)
    styles.append({
        "name": "Side Composition (Focus Left)", 
        "prompt": (
            "COMPOSITION: Asymmetrical framing focusing heavily on the LEFT SIDE of the room.\n"
            "VISUAL PRIORITY: Highlight the furniture and details located near the left wall.\n"
            "CAMERA ANGLE: Slight pan to the left, but keep the original standing position.\n"
            "CRITICAL: Do not move any furniture. Keep the exact arrangement."
        ), 
        "ratio": "16:9"
    })

    # [ìˆ˜ì • 2] ìš°ì¸¡ ê³µê°„ ê°•ì¡°
    styles.append({
        "name": "Side Composition (Focus Right)", 
        "prompt": (
            "COMPOSITION: Asymmetrical framing focusing heavily on the RIGHT SIDE of the room.\n"
            "VISUAL PRIORITY: Highlight the furniture and details located near the right wall.\n"
            "CAMERA ANGLE: Slight pan to the right, but keep the original standing position.\n"
            "CRITICAL: Do not move any furniture. Keep the exact arrangement."
        ), 
        "ratio": "16:9"
    })
    
    count = 0
    for item in analyzed_items:
        if count >= 20: break
        
        label = item['label']
        desc = item.get('description', '')
        box = item.get('box_2d', [0,0,1000,1000])
        
        lens_type = "85mm Telephoto Lens"
        context_instruction = "Include parts of neighboring furniture to prove location."
        position_instruction = "Do NOT move this item. Shoot it exactly where it stands."
        
        if "rug" in label.lower() or "carpet" in label.lower():
            position_instruction = "CRITICAL: The rug MUST be UNDER the sofas/tables. Show furniture legs pressing on it."
            lens_type = "50mm Standard Lens"

        elif any(x in label.lower() for x in ["light", "lamp", "chandelier", "pendant", "sconce"]):
            position_instruction = "CRITICAL: Show the connection to the ceiling/wall. Do NOT crop the cord or chain."
            context_instruction = "ZOOM OUT significantly. You MUST show what this light is illuminating below (e.g., the table or floor). Do NOT fill the frame with just the bulb."
            lens_type = "35mm Wide Lens"

        styles.append({
            "name": f"Detail: {label}",
            "prompt": (
                f"ACT AS: Documentary Interior Photographer.\n"
                f"TASK: Take a candid shot of the '{label}' strictly IN-SITU.\n\n"
                
                f"TARGET VISUALS: {desc}\n"
                f"TARGET COORDINATES: Focus on area {box} (Normalized 0-1000).\n\n"
                
                f"<CRITICAL: ABSOLUTE LAYOUT FREEZE>\n"
                f"1. {position_instruction}\n"
                f"2. {context_instruction}\n"
                "3. **ALLOW OCCLUSION:** It is okay if the object is partially blocked. This adds realism.\n"
                f"4. **LENS:** {lens_type}. Depth of Field is allowed, but geometry change is NOT."
            ),
            "ratio": "4:5"
        })
        count += 1
        
    return styles

def generate_detail_view(original_image_path, style_config, unique_id, index):
    img = None
    try:
        img = Image.open(original_image_path)
        target_ratio = style_config.get('ratio', '16:9')
        
        final_prompt = (
            f"{style_config['prompt']}\n\n"
            "<CRITICAL: LAYOUT FREEZE (PRIORITY #0)>\n"
            "1. **DO NOT MOVE / REARRANGE ANYTHING:** Every existing furniture, lighting fixture, decor item, and their positions must remain EXACTLY the same as the input image.\n"
            "2. **NO NEW OBJECTS:** Do NOT add new objects (no extra vases, cats, books, lamps, shelves, plants, art, etc.).\n"
            "3. **NO REMOVALS:** Do NOT remove existing objects either.\n"
            "4. **CAMERA ONLY:** The close-up must be achieved ONLY by changing the camera framing/crop/zoom. Keep the scene geometry unchanged.\n\n"
            "<OUTPUT REQUIREMENTS>\n"
            "1. Generate a photorealistic high-quality detail view based on the selected camera shot.\n"
            "2. Keep the overall interior style consistent with the main furnished room.\n"
            "3. IMPORTANT: focus on the specified target area only (close-up composition).\n"
            "4. DO NOT add text, labels, logos, or watermarks.\n"
            f"OUTPUT ASPECT RATIO: {target_ratio}"
        )

        safety_settings = {HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE}
        content = [final_prompt, "Original Room Reality (CANVAS - DO NOT ALTER LAYOUT):", img]
        
        response = call_gemini_with_failover(MODEL_NAME, content, {'timeout': 45}, safety_settings)
        if response and hasattr(response, 'candidates') and response.candidates:
            for part in response.parts:
                if hasattr(part, 'inline_data'):
                    timestamp = int(time.time())
                    safe_style_name = "".join([c for c in style_config['name'] if c.isalnum()])[:20]
                    filename = f"detail_{timestamp}_{unique_id}_{index}_{safe_style_name}.png"
                    path = os.path.join("outputs", filename)
                    with open(path, 'wb') as f: f.write(part.inline_data.data)
                    try:
                        if img:
                            img.close()
                    except Exception:
                        pass
                    return f"/outputs/{filename}"
        try:
            if img:
                img.close()
        except Exception:
            pass
        return None
    except Exception as e:
        print(f"!! Detail Generation Error: {e}")
        try:
            if img:
                img.close()
        except Exception:
            pass
        return None

class DetailRequest(BaseModel):
    image_url: str
    moodboard_url: Optional[str] = None
    furniture_data: Optional[List[Dict[str, Any]]] = None 

class RegenerateDetailRequest(BaseModel):
    original_image_url: str
    style_index: int
    moodboard_url: Optional[str] = None
    furniture_data: Optional[List[Dict[str, Any]]] = None 

@app.post("/regenerate-single-detail")
def regenerate_single_detail(req: RegenerateDetailRequest):
    try:
        filename = os.path.basename(req.original_image_url)
        local_path = os.path.join("outputs", filename)
        if not os.path.exists(local_path):
            return JSONResponse(content={"error": "Original image not found"}, status_code=404)
        
        analyzed_items = []
        if req.furniture_data and len(req.furniture_data) > 0:
            print(">> [Single Retry] Using cached furniture data!", flush=True)
            analyzed_items = req.furniture_data
        else:
            analyzed_items = [{"label": "Main Furniture", "description": "High quality furniture matching the room style."}]
        
        dynamic_styles = construct_dynamic_styles(analyzed_items)
        
        if req.style_index < 0 or req.style_index >= len(dynamic_styles):
            return JSONResponse(content={"error": "Invalid style index"}, status_code=400)

        unique_id = uuid.uuid4().hex[:6]
        style = dynamic_styles[req.style_index]
        
        res = generate_detail_view(local_path, style, unique_id, req.style_index + 1)
        
        if res:
            return JSONResponse(content={"url": res, "message": "Success"})
        else:
            return JSONResponse(content={"error": "Generation failed"}, status_code=500)
    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

# [ìˆ˜ì •] main.py ë‚´ë¶€ì˜ generate_details_endpoint í•¨ìˆ˜ êµì²´

@app.post("/generate-details")
def generate_details_endpoint(req: DetailRequest):
    try:
        # 1. ëŒ€ìƒ ì´ë¯¸ì§€ ê²½ë¡œ í™•ë³´
        filename = os.path.basename(req.image_url)
        local_path = os.path.join("outputs", filename)
        if not os.path.exists(local_path):
            return JSONResponse(content={"error": "Original image not found"}, status_code=404)

        unique_id = uuid.uuid4().hex[:6]
        print(f"\n=== [Detail View] ìš”ì²­ ì‹œì‘ ({unique_id}) - Smart Analysis Mode ===", flush=True)

        analyzed_items = []
        
        # 2. ê°€êµ¬ ë°ì´í„° í™•ì¸ (ìºì‹œ or ì‹ ê·œ ë¶„ì„)
        if req.furniture_data and len(req.furniture_data) > 0:
            print(">> [Smart Cache] Using pre-analyzed furniture data!", flush=True)
            analyzed_items = req.furniture_data
        else:
            print(">> [Smart Cache] No cached data found. Starting Analysis...", flush=True)
            
            # [NEW] ë¶„ì„í•  ëŒ€ìƒ ì´ë¯¸ì§€ ê²°ì • ë¡œì§ (ë¬´ë“œë³´ë“œ ìš°ì„  -> ì—†ìœ¼ë©´ ë©”ì¸ ì´ë¯¸ì§€ ì‚¬ìš©)
            target_analysis_path = None
            
            if req.moodboard_url:
                # A. ë¬´ë“œë³´ë“œ URLì´ ìˆëŠ” ê²½ìš° (ê²½ë¡œ íŒŒì‹±)
                if req.moodboard_url.startswith("/assets/"):
                    rel_path = req.moodboard_url.lstrip("/")
                    target_analysis_path = os.path.join(*rel_path.split("/"))
                else:
                    mb_filename = os.path.basename(req.moodboard_url)
                    target_analysis_path = os.path.join("outputs", mb_filename)
            else:
                # B. [í•µì‹¬ ìˆ˜ì •] ë¬´ë“œë³´ë“œê°€ ì—†ìœ¼ë©´? -> ë©”ì¸ ì´ë¯¸ì§€ ë¶„ì„ ëŒ€ìƒì„ ì„¤ì •!
                print(">> [Info] No Moodboard provided. Analyzing the Main Image itself.", flush=True)
                target_analysis_path = local_path

            # 3. ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
            if target_analysis_path and os.path.exists(target_analysis_path):
                try:
                    detected_items = detect_furniture_boxes(target_analysis_path)
                    print(f">> [Deep Analysis] Found {len(detected_items)} items in {target_analysis_path}...", flush=True)
                    
                    with ThreadPoolExecutor(max_workers=10) as executor: # Worker ìˆ˜ ì•½ê°„ ì¦ëŸ‰
                        futures = [executor.submit(analyze_cropped_item, target_analysis_path, item) for item in detected_items]
                        analyzed_items = [f.result() for f in futures]
                        
                    print(f">> [Analysis Done] Items: {[item['label'] for item in analyzed_items]}", flush=True)
                except Exception as e:
                    print(f"!! Analysis Failed: {e}. Using defaults.", flush=True)
                    analyzed_items = []
            else:
                 print(f"!! Target path not found: {target_analysis_path}", flush=True)

            # 4. ë¶„ì„ ì‹¤íŒ¨ ì‹œ ìµœí›„ì˜ ë³´ë£¨ (ê¸°ë³¸ê°’)
            if not analyzed_items:
                 print("!! Fallback to default list.", flush=True)
                 analyzed_items = [{"label": "Sofa"}, {"label": "Chair"}, {"label": "Table"}]
        
        # 5. ë™ì  ìŠ¤íƒ€ì¼ êµ¬ì„± ë° ìƒì„± ìš”ì²­
        dynamic_styles = construct_dynamic_styles(analyzed_items)
        
        generated_results = []
        print(f"ğŸš€ Generating {len(dynamic_styles)} Dynamic Shots...", flush=True)
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []
            for i, style in enumerate(dynamic_styles):
                futures.append((i, executor.submit(generate_detail_view, local_path, style, unique_id, i+1)))
            
            for i, future in futures:
                res = future.result()
                if res: 
                    generated_results.append({"index": i, "url": res})
                
        print(f"=== [Detail View] ì™„ë£Œ: {len(generated_results)}ì¥ ìƒì„±ë¨ ===", flush=True)
        
        if not generated_results:
            return JSONResponse(content={"error": "Failed to generate images"}, status_code=500)

        return JSONResponse(content={
            "details": generated_results,
            "message": "Detail views generated successfully"
        })

    except Exception as e:
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [Detail Error] {e}")
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)

MOODBOARD_SYSTEM_PROMPT = """
ACT AS: An Expert Image Retoucher and Cataloguer.
TASK: Create a "Furniture Inventory Mood Board" by cropping and arranging the ACTUAL furniture from the input photos.

<CRITICAL INSTRUCTION: NO HALLUCINATION>
1. **DO NOT RE-DRAW OR RE-RENDER THE FURNITURE.**
2. **DO NOT CHANGE THE DESIGN.** (If the sofa has round legs, keep them round. If the rug has a specific pattern, keep it EXACTLY.)
3. Your goal is to **EXTRACT** the furniture visual data from the input images and place them on a white background.
4. If you cannot replicate the exact item, crop the best view of it from the source image.

**[STEP 1: SOURCE IDENTIFICATION]**
* Scan all provided images (Main view + Details).
* Find the clearest, best angle for each unique furniture item (Sofa, Chair, Table, Lamp, Rug, etc.).
* Ignore duplicate views. Select the one "Best Shot" for each item.

**[STEP 2: COMPOSITION RULES]**
* **Background:** Pure White (#FFFFFF).
* **Fidelity:** The items in the mood board MUST look identical to the items in the photos. Same color, same texture, same shape.
* **Layout:** Organize them in a grid.
* **Rug:** Show the rug pattern clearly as a flat swatch or perspective view from the photo.

**[STEP 3: TEXT SPECIFICATION]**
Write the specifications under each item in this strict vertical format:

Item Name x Quantity in room EA
Width: Estimated Value mm
Depth: Estimated Value mm
Height: Estimated Value mm

**Exclusion:**
- Do not include walls, ceilings, doors, or windows.
- Focus ONLY on the moveable furniture and key decor (pendant lights, floor lamps).
- OUTPUT RULE: Return a high-quality, 16:9 ratio / 2048x1152pixelimage, .
"""

def generate_moodboard_logic(image_path, unique_id, index, furniture_specs=None):
    img = None
    try:
        img = Image.open(image_path)
        
        final_prompt = MOODBOARD_SYSTEM_PROMPT
        if furniture_specs:
            final_prompt += f"\n\n<CONTEXT: DETECTED FURNITURE LIST>\nUse this list to ensure you capture all key items:\n{furniture_specs}"

        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        response = call_gemini_with_failover(MODEL_NAME, [final_prompt, img], {'timeout': 45}, safety_settings)
        
        if response and hasattr(response, 'candidates') and response.candidates:
            for part in response.parts:
                if hasattr(part, 'inline_data'):
                    timestamp = int(time.time())
                    filename = f"gen_mb_{timestamp}_{unique_id}_{index}.png"
                    path = os.path.join("outputs", filename)
                    with open(path, 'wb') as f: f.write(part.inline_data.data)
                    try:
                        if img:
                            img.close()
                    except Exception:
                        pass
                    return f"/outputs/{filename}"
        try:
            if img:
                img.close()
        except Exception:
            pass
        return None
    except Exception as e:
        print(f"!! Moodboard Gen Error: {e}")
        try:
            if img:
                img.close()
        except Exception:
            pass
        return None

@app.post("/generate-moodboard-options")
def generate_moodboard_options(file: UploadFile = File(...)):
    try:
        unique_id = uuid.uuid4().hex[:8]
        timestamp = int(time.time())
        safe_name = "".join([c for c in file.filename if c.isalnum() or c in "._-"])
        raw_path = os.path.join("outputs", f"ref_room_{timestamp}_{unique_id}_{safe_name}")
        
        with open(raw_path, "wb") as buffer: shutil.copyfileobj(file.file, buffer)
        
        print(f"\n=== [Moodboard Gen] Starting 3 variations for {unique_id} ===", flush=True)

        furniture_specs_text = None
        try:
            print(">> [Moodboard Gen] Analyzing input photo context...", flush=True)
            detected = detect_furniture_boxes(raw_path)
            specs_list = [f"- {item['label']}" for item in detected]
            furniture_specs_text = "\n".join(specs_list)
        except:
            print("!! [Moodboard Gen] Context analysis failed (skipping)")
        
        generated_results = []
        
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(generate_moodboard_logic, raw_path, unique_id, i+1, furniture_specs_text) for i in range(3)]
            for future in futures:
                res = future.result()
                if res: generated_results.append(res)
        
        if not generated_results:
            return JSONResponse(content={"error": "Failed to generate moodboards"}, status_code=500)
            
        return JSONResponse(content={
            "moodboards": generated_results,
            "message": "Moodboards generated successfully"
        })
        
    except Exception as e:
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [Moodboard Gen Error] {e}")
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)


# =========================
# Video MVP (Kling Image-to-Video via Freepik API)
# =========================
class VideoClip(BaseModel):
    url: str
    motion: str = "static"
    effect: str = "none"
    speed: float = 1.0  # [NEW] ê¸°ë³¸ê°’(ì‚¬ìš©ìê°€ ìˆ˜ì • ê°€ëŠ¥)

class VideoCreateRequest(BaseModel):
    clips: List[VideoClip]
    duration: str = "5"
    cfg_scale: float = 0.85
    mode: Optional[str] = None
    target_total_sec: Optional[float] = None
    include_intro_outro: Optional[bool] = None
    # [í•„ìˆ˜ í™•ì¸]
    intro_url: Optional[str] = None
    outro_url: Optional[str] = None


# Use Freepik API key for Kling as well (same header: x-freepik-api-key)
FREEPIK_API_KEY = os.getenv("FREEPIK_API_KEY") or os.getenv("MAGNIFIC_API_KEY")  # fallback for existing env
KLING_MODEL = os.getenv("KLING_MODEL", "kling-v2-5-pro")  # e.g. kling-v2-1-pro, kling-v2-5-pro
KLING_ENDPOINT = os.getenv("KLING_ENDPOINT", f"[https://api.freepik.com/v1/ai/image-to-video/](https://api.freepik.com/v1/ai/image-to-video/){KLING_MODEL}")

# Concurrency controls (avoid 429 bursts)
VIDEO_MAX_CONCURRENCY = int(os.getenv("VIDEO_MAX_CONCURRENCY", "5"))
_video_sem = threading.Semaphore(VIDEO_MAX_CONCURRENCY)

VIDEO_TARGET_FPS = int(os.getenv("VIDEO_TARGET_FPS", "30"))

# Provider side: Kling always returns 5 second clips.
VIDEO_PROVIDER_CLIP_SEC = float(os.getenv("VIDEO_PROVIDER_CLIP_SEC", "5.0"))

# Trimming rules (seconds, on the ORIGINAL clip before speed-up).
# In manual mode we default to using the full 5s clip. In auto_ref mode we override per-scene.
VIDEO_TRIM_HEAD_SEC = float(os.getenv("VIDEO_TRIM_HEAD_SEC", "0.0"))
VIDEO_TRIM_KEEP_SEC = float(os.getenv("VIDEO_TRIM_KEEP_SEC", str(VIDEO_PROVIDER_CLIP_SEC)))

# Requirement: ALWAYS speed up x2 after generation to get snappier motion safely.
VIDEO_SPEED_FACTOR = float(os.getenv("VIDEO_SPEED_FACTOR", "2.0"))

VIDEO_CRF = int(os.getenv("VIDEO_CRF", "18"))

video_jobs: Dict[str, Dict[str, Any]] = {}
video_jobs_lock = threading.Lock()
video_executor = ThreadPoolExecutor(max_workers=2)

def _safe_filename_from_url(url: str) -> str:
    try:
        p = urlparse(url).path
        name = os.path.basename(p)
        return name or f"clip_{uuid.uuid4().hex}.png"
    except:
        return f"clip_{uuid.uuid4().hex}.png"

def _download_to_path(url: str, out_path: Path):
    """
    URLì´ httpë¡œ ì‹œì‘í•˜ë©´ ë‹¤ìš´ë¡œë“œí•˜ê³ ,
    / ë¡œ ì‹œì‘í•˜ë©´ ë¡œì»¬ íŒŒì¼ì„ ë³µì‚¬í•©ë‹ˆë‹¤.
    """
    # [ìˆ˜ì •] ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° (/outputs/... ë“±)
    if url.startswith("/"):
        # ë§¨ ì•ì˜ ìŠ¬ë˜ì‹œ ì œê±° (ì ˆëŒ€ê²½ë¡œ -> ìƒëŒ€ê²½ë¡œ ë³€í™˜, ì˜ˆ: /outputs/a.png -> outputs/a.png)
        local_path = url.lstrip("/")
        
        if not os.path.exists(local_path):
            raise FileNotFoundError(f"Local file not found on server: {local_path}")
            
        # ë‹¨ìˆœíˆ íŒŒì¼ ë³µì‚¬
        with open(local_path, "rb") as src, open(out_path, "wb") as dst:
            shutil.copyfileobj(src, dst)
        return

    # [ê¸°ì¡´] ì›ê²© URLì¸ ê²½ìš° (http://...)
    r = requests.get(url, timeout=120)
    r.raise_for_status()
    with open(out_path, "wb") as f:
        f.write(r.content)

def _run_ffmpeg(cmd: List[str]):
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if proc.returncode != 0:
        raise RuntimeError(proc.stderr.strip() or "ffmpeg failed")

def _ffmpeg_trim_speed(in_path: Path, out_path: Path, start_sec: float, dur_sec: float, speed: float, fps: int):
    # trim -> reset timestamps -> speed up -> fps
    setpts_expr = f"(PTS-STARTPTS)/{speed}" if speed and abs(speed - 1.0) > 1e-6 else "(PTS-STARTPTS)"
    vf = f"trim=start={start_sec}:duration={dur_sec},setpts={setpts_expr},fps={fps}"
    cmd = [
        "ffmpeg", "-y",
        "-i", str(in_path),
        "-vf", vf,
        "-an",
        "-c:v", "libx264",
        "-pix_fmt", "yuv420p",
        "-crf", "10",          # [ìˆ˜ì •] 18 -> 10 (ì´ˆê³ í™”ì§ˆ)
        "-preset", "veryslow", # [ìˆ˜ì •] veryfast -> veryslow (í™”ì§ˆ ìµœìš°ì„ )
        str(out_path),
    ]
    _run_ffmpeg(cmd)

def _ffprobe_wh(path: Path):
    cmd = [
        "ffprobe", "-v", "error",
        "-select_streams", "v:0",
        "-show_entries", "stream=width,height",
        "-of", "json",
        str(path),
    ]
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if proc.returncode != 0:
        raise RuntimeError(proc.stderr.strip() or "ffprobe failed")
    data = json.loads(proc.stdout or "{}")
    st = (data.get("streams") or [{}])[0]
    return int(st.get("width") or 0), int(st.get("height") or 0)

def _ffmpeg_normalize_to(in_path: Path, out_path: Path, target_w: int, target_h: int, fps: int):
    # [FIX] 16:9 ê°€ë¡œ -> 4:5 ì„¸ë¡œ ê°•ì œ ì¤‘ì•™ í¬ë¡­ (Shorts/Reels ìŠ¤íƒ€ì¼)
    # ë³µì¡í•œ íŒ¨ë”©/ë¸”ëŸ¬ ë¡œì§ì„ ì œê±°í•˜ê³ , í™”ë©´ì„ ê½‰ ì±„ìš´ ë’¤ ì¤‘ì•™ì„ ìë¥´ëŠ” ë°©ì‹ ì ìš©
    vf = (
        f"scale={target_w}:{target_h}:force_original_aspect_ratio=increase," # 1. ë¹ˆê³µê°„ ì—†ì´ ê½‰ ì±„ìš°ë„ë¡ í™•ëŒ€ (ë¹„ìœ¨ ìœ ì§€)
        f"crop={target_w}:{target_h}," # 2. ëª©í‘œ í•´ìƒë„ë§Œí¼ ì¤‘ì•™ì„ ì˜ë¼ëƒ„
        f"setsar=1," # 3. í”½ì…€ ë¹„ìœ¨ 1:1 ê°•ì œ (ë³‘í•© ì˜¤ë¥˜ ë°©ì§€)
        f"fps={fps}" # 4. í”„ë ˆì„ë ˆì´íŠ¸ í†µì¼
    )
    cmd = [
        "ffmpeg", "-y",
        "-i", str(in_path),
        "-vf", vf,
        "-an",
        "-c:v", "libx264",
        "-pix_fmt", "yuv420p",
        "-crf", "10",          # [ìˆ˜ì •] 18 -> 10 (ì´ˆê³ í™”ì§ˆ)
        "-preset", "veryslow", # [ìˆ˜ì •] veryfast -> veryslow (í™”ì§ˆ ìµœìš°ì„ )
        str(out_path),
    ]
    _run_ffmpeg(cmd)
import io
import math

def _safe_extract_json(text: str) -> Dict[str, Any]:
    """Extract a JSON object from Gemini text safely."""
    if not text:
        return {}
    t = text.strip()
    if "```json" in t:
        t = t.split("```json", 1)[1].split("```", 1)[0].strip()
    elif "```" in t:
        t = t.split("```", 1)[1].split("```", 1)[0].strip() if t.count("```") >= 2 else t.split("```", 1)[0].strip()
    try:
        obj = json.loads(t)
        return obj if isinstance(obj, dict) else {}
    except Exception:
        pass
    try:
        a = t.find("{")
        b = t.rfind("}")
        if a != -1 and b != -1 and b > a:
            obj = json.loads(t[a:b+1])
            return obj if isinstance(obj, dict) else {}
    except Exception:
        pass
    return {}

def _clip_url_to_image_bytes(url: str) -> bytes:
    """Supports data URI, local path (/...), and remote URL."""
    if url.startswith("data:image/"):
        try:
            _, encoded = url.split(",", 1)
            return base64.b64decode(encoded)
        except Exception:
            return base64.b64decode(url)
    if url.startswith("/"):
        local_path = url.lstrip("/")
        if not os.path.exists(local_path):
            raise FileNotFoundError(f"Image not found on server: {local_path}")
        return Path(local_path).read_bytes()
    r = requests.get(url, timeout=120)
    r.raise_for_status()
    return r.content

def _find_static_image(prefix: str) -> Optional[Path]:
    """
    Finds static/{prefix}.* (png/jpg/jpeg/webp). Example: intro.png, outro.jpg
    """
    static_dir = Path("static")
    if not static_dir.exists():
        return None
    exts = ["png", "jpg", "jpeg", "webp"]
    cand = []
    for ext in exts:
        cand.extend(static_dir.glob(f"{prefix}*.{ext}"))
        cand.extend(static_dir.glob(f"{prefix.upper()}*.{ext}"))
        cand.extend(static_dir.glob(f"{prefix.capitalize()}*.{ext}"))
    cand = sorted(set(cand))
    return cand[0] if cand else None

def _ffmpeg_image_to_video(image_path: Path, out_path: Path, dur_sec: float, target_w: int, target_h: int, fps: int):
    """
    Turns a still image into a short video segment.
    [FIX] Removed fade in/out filters to ensure purely static image.
    """
    # [ìˆ˜ì •] í˜ì´ë“œ íš¨ê³¼ ì œê±°, í•´ìƒë„/ë¹„ìœ¨ë§Œ ë§ì¶¤
    vf = (
        f"scale={target_w}:{target_h}:force_original_aspect_ratio=increase,"
        f"crop={target_w}:{target_h},setsar=1,fps={fps}"
    )
    cmd = [
        "ffmpeg", "-y",
        "-loop", "1",
        "-i", str(image_path),
        "-t", str(dur_sec),
        "-vf", vf,
        "-an",
        "-c:v", "libx264",
        "-pix_fmt", "yuv420p",
        "-crf", "10",          # [ìˆ˜ì •] 18 -> 10
        "-preset", "veryslow", # [ìˆ˜ì •] veryfast -> veryslow
        str(out_path),
    ]
    _run_ffmpeg(cmd)

# [NEW] ëª¨ì…˜ê³¼ ì´í™íŠ¸ë¥¼ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
def _kling_prompts_dynamic(motion: str, effect: str) -> Dict[str, str]:
    # 1. ê¸°ë³¸ í’ˆì§ˆ ë° ìœ ì§€ í”„ë¡¬í”„íŠ¸
    base_keep = (
        "High quality interior video, photorealistic, 8k. "
        "Keep ALL furniture and layout exactly the same as the input image. "
        "No warping, no distortion. "
    )
    
    # 2. ëª¨ì…˜ í”„ë¡¬í”„íŠ¸ ë§¤í•‘
    motion_map = {
        "static": "Static camera shot, extremely subtle movement.",
        "orbit_r_slow": "Slow orbit rotation to the right, keeping the subject centered, smooth movement.",
        "orbit_l_slow": "Slow orbit rotation to the left, keeping the subject centered, smooth movement.",
        "orbit_r_fast": "Fast orbit rotation to the right, dynamic camera movement.",
        "orbit_l_fast": "Fast orbit rotation to the left, dynamic camera movement.",
        "zoom_in_slow": "Slow camera dolly-in at eye-level. Move straight forward without shaking or walking bob. Smooth cinematic push.",
        "zoom_out_slow": "Slow camera dolly-out at eye-level. Move straight backward without shaking or walking bob. Smooth cinematic pull.",
        "zoom_in_fast": "Fast camera dolly-in at eye-level. Rapid straight movement towards the subject.",
        "zoom_out_fast": "Fast camera dolly-out at eye-level. Rapid straight movement away from the subject.",
    }
    
    # 3. ì´í™íŠ¸ í”„ë¡¬í”„íŠ¸ ë§¤í•‘
    effect_map = {
        "none": "Natural lighting, static environment.",
        "sunlight": "Sunlight beams moving across the room, time-lapse shadow movement on the floor and furniture.",
        "lights_on": "Lighting transition: starts with lights off or dim, then lights turn on brightly. Cinematic illumination reveal.",
        "blinds": "Curtains or blinds moving gently in the wind near the window.",
        "plants": "Indoor plants and foliage swaying gently in a soft breeze.",
        "door_open": "A door, cabinet door, or glass door in the scene slowly opens.",
    }

    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
    p_motion = motion_map.get(motion, motion_map["static"])
    p_effect = effect_map.get(effect, effect_map["none"])
    
    final_prompt = f"{base_keep} {p_motion} {p_effect}"

    # ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
    neg = (
        "human, person, walking, shaking camera, shaky footage, "
        "changing furniture, melting objects, distorted geometry, "
        "text, watermark, logo, frame borders, low quality, cartoon"
    )
    
    return {"prompt": final_prompt, "negative_prompt": neg}

def _freepik_kling_create_task(image_b64: str, prompt: str, negative_prompt: str, duration: str, cfg_scale: float) -> str:
    if not FREEPIK_API_KEY:
        raise RuntimeError("FREEPIK_API_KEY (or MAGNIFIC_API_KEY) is not set.")
    payload = {
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "duration": duration,
        "cfg_scale": cfg_scale,
        "image": image_b64
    }
    headers = {"x-freepik-api-key": FREEPIK_API_KEY, "Content-Type": "application/json"}
    with _video_sem:
        r = requests.post(KLING_ENDPOINT, headers=headers, json=payload, timeout=180)
    if r.status_code == 429:
        raise RuntimeError("Kling/Freepik rate limit hit (429). Try again later or lower VIDEO_MAX_CONCURRENCY.")
    if not r.ok:
        raise RuntimeError(f"Kling create failed ({r.status_code}): {r.text[:500]}")
    
    data = r.json()
    
    # âœ… ë””ë²„ê¹…: ì‹¤ì œ ì‘ë‹µ êµ¬ì¡° ì¶œë ¥
    print(f"ğŸ” [DEBUG] Kling API Response: {json.dumps(data, indent=2)}", flush=True)
    
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œ ì‹œë„
    task_id = (
        data.get("task_id") or 
        data.get("id") or 
        data.get("data", {}).get("task_id") or 
        data.get("data", {}).get("id") or
        data.get("result", {}).get("task_id") or
        data.get("taskId")
    )
    
    if not task_id:
        print(f"âŒ [ERROR] Could not find task_id. Full response keys: {list(data.keys())}", flush=True)
        raise RuntimeError(f"No task_id returned from Kling create. Response: {json.dumps(data)[:300]}")
    
    print(f"âœ… [SUCCESS] Task created: {task_id}", flush=True)
    return task_id

import math # í•¨ìˆ˜ ìƒë‹¨ì´ë‚˜ íŒŒì¼ ìµœìƒë‹¨ì— import math í•„ìš”

def _freepik_kling_poll(task_id: str, job_id: str, clip_index: int, total_clips: int, timeout_sec: int = 600) -> str:
    headers = {"x-freepik-api-key": FREEPIK_API_KEY}
    start = time.time()
    poll_count = 0
    
    # [UX] ê° í´ë¦½ë‹¹ í• ë‹¹í•  ìµœëŒ€ ì§„í–‰ë¥  (ì „ì²´ì˜ 90%ë¥¼ í´ë¦½ ìƒì„±ì— ë¶„ë°°)
    # ì˜ˆ: í´ë¦½ì´ 1ê°œë©´ 90%ê¹Œì§€, 2ê°œë©´ ê°œë‹¹ 45%ê¹Œì§€ í• ë‹¹
    clip_share_percent = 90 / max(1, total_clips)
    clip_start_percent = clip_index * clip_share_percent

    while True:
        if time.time() - start > timeout_sec:
            raise RuntimeError("Kling task timeout.")
        
        poll_count += 1
        
        # 1. API í˜¸ì¶œ (ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ë°©ì–´)
        try:
            with _video_sem:
                r = requests.get(f"{KLING_ENDPOINT}/{task_id}", headers=headers, timeout=60)
            
            if not r.ok:
                # 500 ì—ëŸ¬ ë“±ì€ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                if r.status_code >= 500:
                    print(f"âš ï¸ [Server Warning] {r.status_code}. Retrying...", flush=True)
                    time.sleep(3)
                    continue
                raise RuntimeError(f"Kling status failed ({r.status_code}): {r.text[:300]}")
                
            st = r.json()
            
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ [Network Warning] Polling failed temporarily: {e}. Retrying...", flush=True)
            time.sleep(3)
            continue

        # 2. [FIX] ë°ì´í„° êµ¬ì¡° ë°©ì–´ ë¡œì§ (AttributeError 'str' object ë°©ì§€)
        data = st.get("data", {})
        status = "UNKNOWN"

        if isinstance(data, dict):
            status = data.get("status", "").upper()
        elif isinstance(st, dict):
             # dataê°€ ì—†ê±°ë‚˜ ë¬¸ìì—´ì´ë©´ top-levelì—ì„œ status í™•ì¸
            status = st.get("status", "").upper()
        
        # 3. [FIX] ì§„í–‰ë¥  ë¡œì§ ê°œì„  (15% ë©ˆì¶¤ í•´ê²°)
        # ë¡œê·¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì²œì²œíˆ ì˜¤ë¥´ì§€ë§Œ 100%ëŠ” ë„˜ì§€ ì•Šê²Œ ì„¤ì •
        # poll_countê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ clip_share_percentì˜ 95% ìˆ˜ì¤€ê¹Œì§€ ì ì§„ì ìœ¼ë¡œ ì ‘ê·¼
        simulated_progress = clip_share_percent * 0.95 * (1 - math.exp(-0.05 * poll_count))
        
        current_total_progress = int(clip_start_percent + simulated_progress)
        
        # ë¡œê·¸ ì¶œë ¥ (ì‚¬ìš©ì ì•ˆì‹¬ìš©)
        if poll_count <= 3 or poll_count % 5 == 0:
            print(f"ğŸ” [Poll #{poll_count}] Clip {clip_index+1}/{total_clips} Status: {status} (Progress: {current_total_progress}%)", flush=True)

        with video_jobs_lock:
            if job_id in video_jobs:
                video_jobs[job_id]["progress"] = current_total_progress
                # ë©”ì‹œì§€ì— ì‹¤ì œ ì„œë²„ ìƒíƒœ í¬í•¨
                video_jobs[job_id]["message"] = f"Generating clip {clip_index+1}/{total_clips}: {status}..."
        
        # 4. ì™„ë£Œ ì²˜ë¦¬
        if status in ("COMPLETED", "SUCCEEDED", "SUCCESS", "DONE"):
            print(f"âœ… [COMPLETED] Clip {clip_index+1}/{total_clips}. Fetching URL...", flush=True)
            
            # generated í•„ë“œ ì•ˆì „ ì¶”ì¶œ
            generated = []
            if isinstance(data, dict):
                generated = data.get("generated", [])
            elif isinstance(st, dict):
                generated = st.get("generated", [])

            # ì™„ë£Œë˜ì—ˆëŠ”ë° URLì´ ë°”ë¡œ ì•ˆ ëœ¨ëŠ” ê²½ìš° ëŒ€ê¸°
            retry_count = 0
            while not generated and retry_count < 5:
                print(f"â³ [WAIT] Generated array empty, retrying... ({retry_count+1}/5)", flush=True)
                time.sleep(2)
                retry_count += 1
                
                with _video_sem:
                    r = requests.get(f"{KLING_ENDPOINT}/{task_id}", headers=headers, timeout=60)
                if r.ok:
                    st = r.json()
                    data = st.get("data", {})
                    if isinstance(data, dict):
                        generated = data.get("generated", [])
                    else:
                        generated = st.get("generated", [])

            # URL ì°¾ê¸°
            url = None
            if generated and len(generated) > 0:
                first = generated[0]
                if isinstance(first, dict):
                    url = first.get("url") or first.get("video")
                elif isinstance(first, str):
                    url = first
            
            if not url and isinstance(data, dict):
                 url = data.get("video_url") or data.get("url") or data.get("video")
            
            if not url:
                url = st.get("result_url") or st.get("video_url")

            if url:
                print(f"âœ… [SUCCESS] Found URL: {url[:60]}...", flush=True)
                return url
            
            print(f"âŒ [ERROR] Completed but no URL. Response dump:", flush=True)
            print(json.dumps(st, indent=2), flush=True)
            raise RuntimeError("Kling completed but no result URL found.")
        
        if status in ("FAILED", "ERROR", "CANCELLED"):
            error_msg = "Unknown error"
            if isinstance(data, dict):
                error_msg = data.get("error") or data.get("message") or error_msg
            elif isinstance(data, str):
                error_msg = data
            elif isinstance(st, dict):
                 error_msg = st.get("error") or st.get("message") or error_msg
            
            raise RuntimeError(f"Kling task failed: {error_msg}")
        
        time.sleep(2)

def _image_url_to_b64(url: str) -> str:
    """
    ì´ë¯¸ì§€ URL(í˜¹ì€ ë¡œì»¬ ê²½ë¡œ)ì„ ë°›ì•„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    # [ìˆ˜ì •] ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
    if url.startswith("/"):
        local_path = url.lstrip("/")
        if not os.path.exists(local_path):
            raise FileNotFoundError(f"Local file not found for b64 conversion: {local_path}")
            
        with open(local_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    # [ê¸°ì¡´] ì›ê²© URLì¸ ê²½ìš°
    r = requests.get(url, timeout=120)
    r.raise_for_status()
    return base64.b64encode(r.content).decode("utf-8")

# -----------------------------------------------------------------------------
# [NEW] ë‹¨ì¼ í´ë¦½ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬ ì‹¤í–‰ìš©)
# -----------------------------------------------------------------------------
# =========================================================
# [NEW] 2-Step Video Logic (Source Gen -> Final Compile)
# =========================================================

# --- 1. Request Models (ë°ì´í„° ëª¨ë¸ ì •ì˜) ---
class SourceItem(BaseModel):
    url: str
    motion: str = "static"
    effect: str = "none"

class SourceGenRequest(BaseModel):
    items: List[SourceItem]
    cfg_scale: float = 0.5

class CompileClip(BaseModel):
    video_url: str
    speed: float = 1.0
    trim_start: float = 0.0
    trim_end: float = 5.0

class CompileRequest(BaseModel):
    clips: List[CompileClip]
    include_intro_outro: bool = False
    intro_url: Optional[str] = None
    outro_url: Optional[str] = None

def _generate_raw_only(idx, item, job_id, out_dir, cfg_scale):
    """
    Step 1: ì†ŒìŠ¤ ìƒì„± ë¡œì§
    - Static & No Effect: FFmpegë¡œ ì¦‰ì‹œ ë³€í™˜ (Fast, Free)
    - Motion or Effect: Kling AI í˜¸ì¶œ (Slow, Cost)
    """
    filename = f"source_{job_id}_{idx}.mp4"
    out_path = out_dir / filename
    
    # [ìµœì í™”] ì›€ì§ì„ë„ ì—†ê³ , íš¨ê³¼ë„ ì—†ìœ¼ë©´ -> ê·¸ëƒ¥ ì´ë¯¸ì§€ 5ì´ˆ ì˜ìƒìœ¼ë¡œ ë³€í™˜ (Kling X)
    if item.motion == "static" and item.effect == "none":
        print(f"ğŸš€ [Clip {idx}] Static detected. Skipping Kling (Fast generation).", flush=True)
        temp_img = out_dir / f"temp_src_{job_id}_{idx}.png"
        try:
            # 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            _download_to_path(item.url, temp_img)
            
            # [ìˆ˜ì •] 1080, 1920 (ì„¸ë¡œ) íŒŒë¼ë¯¸í„° í™•ì¸
            _ffmpeg_image_to_video(
                temp_img, out_path, 
                5.0, 
                1080, 1920, # <--- ì—¬ê¸°ê°€ 1080, 1920 ì´ì–´ì•¼ í•¨
                VIDEO_TARGET_FPS
            )
            return out_path
        except Exception as e:
            print(f"Static Gen Error: {e}")
            raise e
        finally:
            if temp_img.exists(): temp_img.unlink()

    # ---------------------------------------------------------
    # ê·¸ ì™¸ (ëª¨ì…˜ì´ë‚˜ ì´í™íŠ¸ê°€ ìˆëŠ” ê²½ìš°) -> Kling í˜¸ì¶œ
    # ---------------------------------------------------------
    print(f"ğŸ¥ [Clip {idx}] Kling AI Generating... ({item.motion}/{item.effect})", flush=True)
    
    prompts = _kling_prompts_dynamic(item.motion, item.effect)
    img_b64 = _image_url_to_b64(item.url)
    
    # 5ì´ˆ ìƒì„± ìš”ì²­
    task_id = _freepik_kling_create_task(
        img_b64, prompts["prompt"], prompts["negative_prompt"], 
        "5", cfg_scale
    )
    
    # í´ë§ ëŒ€ê¸°
    video_url = _freepik_kling_poll(task_id, job_id, idx, 1)
    
    # ë‹¤ìš´ë¡œë“œ
    _download_to_path(video_url, out_path)
    
    return out_path

def _run_source_generation(job_id: str, items: List[SourceItem], cfg_scale: float):
    try:
        with video_jobs_lock:
            video_jobs[job_id] = {"status": "RUNNING", "message": "Initializing...", "progress": 0, "results": []}

        out_dir = Path("outputs")
        out_dir.mkdir(parents=True, exist_ok=True)
        
        total_steps = len(items)
        results_map = [None] * total_steps # ìˆœì„œ ë³´ì¥ìš©
        
        # ë³‘ë ¬ ì‹¤í–‰ (ìµœëŒ€ 5ê°œ ë™ì‹œ)
        with ThreadPoolExecutor(max_workers=VIDEO_MAX_CONCURRENCY) as executor:
            future_map = {}
            for i, item in enumerate(items):
                future = executor.submit(_generate_raw_only, i, item, job_id, out_dir, cfg_scale)
                future_map[future] = i

            completed_count = 0
            for future in as_completed(future_map):
                idx = future_map[future]
                try:
                    path = future.result() 
                    if path:
                        # ì›¹ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œë¡œ ì €ì¥
                        results_map[idx] = f"/outputs/{path.name}"
                except Exception as e:
                    print(f"Clip {idx} failed: {e}")
                    results_map[idx] = None # ì‹¤íŒ¨ ì‹œ None
                
                completed_count += 1
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                with video_jobs_lock:
                    video_jobs[job_id]["progress"] = int((completed_count / total_steps) * 100)
                    video_jobs[job_id]["message"] = f"Generated {completed_count}/{total_steps} clips"

        # ì™„ë£Œ
        with video_jobs_lock:
            video_jobs[job_id]["status"] = "COMPLETED"
            video_jobs[job_id]["results"] = results_map # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            video_jobs[job_id]["message"] = "Source generation complete."

    except Exception as e:
        print(f"Source Gen Critical Error: {e}")
        traceback.print_exc()
        with video_jobs_lock:
            video_jobs[job_id]["status"] = "FAILED"
            video_jobs[job_id]["error"] = str(e)

# --- 3. Step 2: Final Compile (ìë¥´ê¸°/ë°°ì†/ë³‘í•©) ---
def _run_final_compile(job_id: str, req: CompileRequest):
    try:
        with video_jobs_lock:
            video_jobs[job_id] = {"status": "RUNNING", "message": "Compiling...", "progress": 0}
            
        out_dir = Path("outputs")
        processed_paths = []
        
        total_clips = len(req.clips)
        
        # 1. ê° í´ë¦½ ê°€ê³µ (Trim -> Speed -> Resize)
        for i, clip in enumerate(req.clips):
            if not clip.video_url: continue
            
            # ì›ë³¸ íŒŒì¼ í™•ë³´ (ë¡œì»¬ì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ)
            src_name = _safe_filename_from_url(clip.video_url)
            local_src = out_dir / src_name
            if not local_src.exists():
                _download_to_path(clip.video_url, local_src)
            
            final_path = out_dir / f"proc_{job_id}_{i}.mp4"
            
            # íŒŒë¼ë¯¸í„° ê³„ì‚°
            t_start = max(0.0, clip.trim_start)
            t_end = min(5.0, clip.trim_end)
            if t_end <= t_start: t_end = 5.0
            
            dur = t_end - t_start
            # ì†ë„ ì•ˆì „ì¥ì¹˜ (0ì´ë©´ 1.0ìœ¼ë¡œ)
            speed = clip.speed if clip.speed > 0.1 else 1.0
            
            # FFmpeg í•„í„° êµ¬ì„±:
            # 1. trim: êµ¬ê°„ ìë¥´ê¸°
            # 2. setpts: ì†ë„ ì¡°ì ˆ ((PTS-STARTPTS)/speed)
            # 3. scale/crop: í•´ìƒë„ ê°•ì œ í†µì¼ (1080x1920 ë“± ê¸°ì¡´ ì„¤ì • ë”°ë¦„)
            # 4. setsar=1: í”½ì…€ ë¹„ìœ¨ ì´ˆê¸°í™” (ë³‘í•© ì˜¤ë¥˜ ë°©ì§€)
            setpts = f"(PTS-STARTPTS)/{speed}"
            
# [ìˆ˜ì •] 1080x1920 ì„¸ë¡œí˜•(9:16) ê°•ì œ ì ìš©
            vf = (
                f"trim=start={t_start}:duration={dur},setpts={setpts},"
                f"scale=1080:1920:force_original_aspect_ratio=increase," # 9:16 ë¹„ìœ¨ë¡œ ëŠ˜ë¦¬ê³ 
                f"crop=1080:1920,setsar=1,fps={VIDEO_TARGET_FPS}"       # ì¤‘ì•™ í¬ë¡­
            )
            
            cmd = [
                "ffmpeg", "-y", "-i", str(local_src),
                "-vf", vf, "-an", 
                "-c:v", "libx264", "-pix_fmt", "yuv420p", 
                "-preset", "veryslow", # [ìˆ˜ì •] veryfast -> veryslow
                "-crf", "10",          # [ìˆ˜ì •] 18 -> 10
                str(final_path)
            ]
            _run_ffmpeg(cmd)
            processed_paths.append(final_path)
            
            # ì§„í–‰ë¥  (0~80%)
            with video_jobs_lock:
                video_jobs[job_id]["progress"] = int(((i + 1) / total_clips) * 80)

        # 2. ë³‘í•© (Concat)
        if not processed_paths: raise RuntimeError("No clips to merge")
        
        list_file = out_dir / f"list_{job_id}.txt"
        with open(list_file, "w", encoding="utf-8") as f:
            for p in processed_paths:
                f.write(f"file '{p.resolve().as_posix()}'\n")
        
        final_out = out_dir / f"final_{job_id}.mp4"
        # Concat ì‹¤í–‰
        _run_ffmpeg(["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", str(list_file), "-c", "copy", str(final_out)])
        
        result_url = f"/outputs/{final_out.name}"
        
        with video_jobs_lock:
            video_jobs[job_id]["status"] = "COMPLETED"
            video_jobs[job_id]["result_url"] = result_url
            video_jobs[job_id]["progress"] = 100
            
    except Exception as e:
        print(f"Compile Error: {e}")
        traceback.print_exc()
        with video_jobs_lock:
            video_jobs[job_id]["status"] = "FAILED"
            video_jobs[job_id]["error"] = str(e)

# --- 4. API Endpoints (New) ---

@app.post("/video-mvp/generate-sources")
async def api_generate_sources(req: SourceGenRequest):
    job_id = uuid.uuid4().hex
    with video_jobs_lock:
        video_jobs[job_id] = {"status": "QUEUED", "progress": 0}
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
    threading.Thread(target=_run_source_generation, args=(job_id, req.items, req.cfg_scale)).start()
    return {"job_id": job_id}

@app.post("/video-mvp/compile")
async def api_compile_final(req: CompileRequest):
    job_id = uuid.uuid4().hex
    with video_jobs_lock:
        video_jobs[job_id] = {"status": "QUEUED", "progress": 0}
        
    threading.Thread(target=_run_final_compile, args=(job_id, req)).start()
    return {"job_id": job_id}

@app.get("/video-mvp/status/{job_id}")
async def video_mvp_status(job_id: str):
    with video_jobs_lock:
        st = video_jobs.get(job_id)
    if not st:
        return JSONResponse({"status": "NOT_FOUND", "message": "Job not found"}, status_code=404)
    return st


# --- Auto Cleanup System ---
RETENTION_SECONDS = 7 * 24 * 60 * 60  # 7 days 
CLEANUP_INTERVAL = 600

def auto_cleanup_task():
    while True:
        try:
            now = time.time()
            
            # 1. íŒŒì¼ ì •ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            deleted_count = 0
            folder = "outputs"
            if os.path.exists(folder):
                for filename in os.listdir(folder):
                    file_path = os.path.join(folder, filename)
                    if os.path.isfile(file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.mp4')):
                        file_age = now - os.path.getmtime(file_path)
                        if file_age > RETENTION_SECONDS:
                            try:
                                os.remove(file_path)
                                deleted_count += 1
                            except Exception: pass
            
            # 2. [FIX] ë©”ëª¨ë¦¬ ì •ë¦¬: ì™„ë£Œë˜ì—ˆê±°ë‚˜ ì˜¤ë˜ëœ Job ID ì‚­ì œ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
            # Job ìƒì„± í›„ 24ì‹œê°„(86400ì´ˆ) ì§€ë‚œ ê¸°ë¡ì€ ì‚­ì œ
            JOB_RETENTION = 86400 
            with video_jobs_lock:
                # ë”•ì…”ë„ˆë¦¬ë¥¼ ìˆœíšŒí•˜ë©° ì‚­ì œí•´ì•¼ í•˜ë¯€ë¡œ í‚¤ ë¦¬ìŠ¤íŠ¸ ë³µì‚¬ ì‚¬ìš©
                for jid in list(video_jobs.keys()):
                    # progressê°€ 100ì´ê±°ë‚˜ failedì¸ ìƒíƒœì—ì„œ ì˜¤ë˜ëœ ê²ƒ, í˜¹ì€ ê·¸ëƒ¥ ë„ˆë¬´ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ
                    # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí•˜ê²Œ ìƒì„± ì‹œê°„ì„ ë³„ë„ ì¶”ì  ì•ˆí•˜ë¯€ë¡œ, ì¼ë‹¨ 100% ì™„ë£Œëœ ê±´ ë°”ë¡œ ì§€ìš°ì§€ ì•Šê³ (ë‹¤ìš´ë¡œë“œ ìœ„í•´),
                    # ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ ì •ì±…ì´ í•„ìš”í•¨.
                    # ê°„ë‹¨í•˜ê²Œ: video_jobsì— timestamp í•„ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì •ì„ì´ë‚˜,
                    # í˜„ì¬ êµ¬ì¡°ìƒ 'ë„ˆë¬´ ë§ì•„ì§€ë©´ ê°•ì œ ì •ë¦¬' ë°©ì‹ìœ¼ë¡œ êµ¬í˜„.
                    if len(video_jobs) > 1000: # í˜¹ì‹œ 1000ê°œê°€ ë„˜ì–´ê°€ë©´
                        video_jobs.pop(jid, None) # ì•ì—ì„œë¶€í„° í•˜ë‚˜ ì§€ì›€ (Python 3.7+ ë”•ì…”ë„ˆë¦¬ëŠ” ì‚½ì… ìˆœì„œ ìœ ì§€ë˜ë¯€ë¡œ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œë¨)
            
            if deleted_count > 0:
                print(f"âœ¨ [System] Cleaned up {deleted_count} old files.", flush=True)
                
        except Exception as e:
            print(f"!! [Cleanup Error] {e}", flush=True)
        time.sleep(CLEANUP_INTERVAL)

import threading
import subprocess
from urllib.parse import urlparse
from pathlib import Path
cleanup_thread = threading.Thread(target=auto_cleanup_task, daemon=True)
cleanup_thread.start()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=False, log_level="info")
